{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f7e41341c62a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "nn.BatchNorm2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r= models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 0 ---------- Conv2d(13, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "-- 1 ---------- BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-- 2 ---------- ReLU(inplace)\n",
      "-- 3 ---------- MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "-- 4 ---------- Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "-- 5 ---------- Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "-- 6 ---------- Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "-- 7 ---------- Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "-- 8 ---------- AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "-- 9 ---------- Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for child in model.children():\n",
    "    #print(child)\n",
    "    print(\"--\", counter,'----------', child)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing last layer\n",
    "num_final_in = model.fc.in_features\n",
    "\n",
    "# The final layer of the model is model.fc so we can basically just overwrite it \n",
    "# to have the output = number of classes we need. Say, 300 classes.\n",
    "NUM_CLASSES = 3\n",
    "model.fc = nn.Linear(num_final_in, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]          40,768\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 3]           1,539\n",
      "================================================================\n",
      "Total params: 11,209,411\n",
      "Trainable params: 11,209,411\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.49\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.76\n",
      "Estimated Total Size (MB): 108.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (13,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image_1 = np.random.rand(224,224,12)\n",
    "dummy_image_2 = np.random.rand(224,224,12)\n",
    "dummy_image_3 = np.random.rand(224,224,12)\n",
    "dummy_image_4 = np.random.rand(224,224,12)\n",
    "dummy_image_5 = np.random.rand(224,224,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Loss function, Optimizer etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "els = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  letâ€™s write a general function to train a model\n",
    "We will illustrate: \n",
    "1. Scheduling the learning rate\n",
    "2. Saving the best model\n",
    "\n",
    "In the following, parameter scheduler is an LR scheduler object from torch.optim.lr_scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4349411b3c3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, els, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition['train'] = ['id-1', 'id-2', 'id-3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition['validation'] = ['id-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['id-1'] = 0\n",
    "labels['id-2'] = 1\n",
    "labels['id-3'] = 2\n",
    "labels['id-4'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom Dataset classes\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = np.random.randn(100,12,224,224)\n",
    "numpy_target = np.random.randint(0,3,size=(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 12, 224, 224)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(numpy_data.shape)\n",
    "print(numpy_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 1, 1, 2, 2, 0, 2, 1, 0, 0, 2, 1, 0, 0, 2, 1, 1, 2, 0,\n",
       "       2, 2, 0, 0, 1, 2, 2, 2, 0, 2, 1, 1, 1, 0, 0, 1, 2, 0, 1, 2, 1, 2,\n",
       "       1, 1, 2, 1, 1, 0, 2, 1, 2, 1, 2, 2, 0, 0, 2, 0, 0, 1, 1, 1, 2, 0,\n",
       "       0, 1, 2, 1, 0, 1, 1, 0, 2, 0, 1, 2, 1, 2, 2, 2, 2, 0, 1, 0, 1, 1,\n",
       "       2, 0, 0, 1, 0, 1, 2, 1, 2, 1, 0, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, 0, 0, 0, 1, 2, 2, 1, 2, 0, 1, 2, 1, 1, 1, 2, 0, 1, 2, 2,\n",
       "       1, 2, 1, 1, 1, 0, 0, 2, 1, 2, 0, 0, 0, 1, 2, 0, 1, 0, 2, 0, 1, 1,\n",
       "       2, 1, 0, 2, 1, 0, 1, 0, 1, 1, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 0,\n",
       "       2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(numpy_data, numpy_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.__len__())\n",
    "print(dataset.__getitem__(9)[1])\n",
    "#print(dataset.__getitem__(2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available() )\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch idx 0, data shape torch.Size([16, 12, 224, 224]), target shape torch.Size([16])\n",
      "Batch idx 1, data shape torch.Size([16, 12, 224, 224]), target shape torch.Size([16])\n",
      "Batch idx 2, data shape torch.Size([16, 12, 224, 224]), target shape torch.Size([16])\n",
      "Batch idx 3, data shape torch.Size([16, 12, 224, 224]), target shape torch.Size([16])\n",
      "Batch idx 4, data shape torch.Size([16, 12, 224, 224]), target shape torch.Size([16])\n",
      "Batch idx 5, data shape torch.Size([16, 12, 224, 224]), target shape torch.Size([16])\n",
      "Batch idx 6, data shape torch.Size([4, 12, 224, 224]), target shape torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(loader):\n",
    "    print('Batch idx {}, data shape {}, target shape {}'.format(batch_idx, data.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        \n",
    "        for i, (images,labels) in enumerate(loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            #Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            \n",
    "            print('Epoch [{}/{}],  Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, 100, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "els = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3],  Step [1/100], Loss: 1.1542\n",
      "Epoch [1/3],  Step [2/100], Loss: 1.1598\n",
      "Epoch [1/3],  Step [3/100], Loss: 1.4662\n",
      "Epoch [1/3],  Step [4/100], Loss: 1.0993\n",
      "Epoch [1/3],  Step [5/100], Loss: 1.0935\n",
      "Epoch [1/3],  Step [6/100], Loss: 1.1134\n",
      "Epoch [1/3],  Step [7/100], Loss: 1.1910\n",
      "Epoch [2/3],  Step [1/100], Loss: 0.9405\n",
      "Epoch [2/3],  Step [2/100], Loss: 0.9349\n",
      "Epoch [2/3],  Step [3/100], Loss: 1.0179\n",
      "Epoch [2/3],  Step [4/100], Loss: 1.1639\n",
      "Epoch [2/3],  Step [5/100], Loss: 1.2163\n",
      "Epoch [2/3],  Step [6/100], Loss: 0.9425\n",
      "Epoch [2/3],  Step [7/100], Loss: 0.8593\n",
      "Epoch [3/3],  Step [1/100], Loss: 0.7845\n",
      "Epoch [3/3],  Step [2/100], Loss: 0.7759\n",
      "Epoch [3/3],  Step [3/100], Loss: 0.7827\n",
      "Epoch [3/3],  Step [4/100], Loss: 0.8040\n",
      "Epoch [3/3],  Step [5/100], Loss: 0.8175\n",
      "Epoch [3/3],  Step [6/100], Loss: 0.9009\n",
      "Epoch [3/3],  Step [7/100], Loss: 0.7338\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, els, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data_test = np.random.randn(10,12,224,224)\n",
    "numpy_target_test = np.random.randint(0,3,size=(10))\n",
    "dataset = MyDataset(numpy_data_test, numpy_target_test)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch idx 0, data shape torch.Size([4, 12, 224, 224]), target shape torch.Size([4])\n",
      "Batch idx 1, data shape torch.Size([4, 12, 224, 224]), target shape torch.Size([4])\n",
      "Batch idx 2, data shape torch.Size([2, 12, 224, 224]), target shape torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(loader):\n",
    "    print('Batch idx {}, data shape {}, target shape {}'.format(batch_idx, data.shape, target.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def eval_model(model,test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        print('Test Accuracy on 10 images: {} %'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-a5b22135790d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-158a695f9f2a>\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "eval_model(model, loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data from Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 184, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(112, 169, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(99, 96, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(146, 216, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(103, 98, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(161, 180, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(88, 127, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(81, 82, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(96, 71, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(126, 110, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(98, 148, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(80, 148, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(151, 155, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(130, 124, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(115, 122, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(86, 102, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(72, 84, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(138, 107, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(67, 55, 3)\n",
      "0 0\n",
      "4 5\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(165, 116, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(78, 135, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(77, 85, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(162, 141, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(91, 135, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(105, 103, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(135, 168, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(105, 90, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(94, 90, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(84, 102, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(81, 114, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(152, 232, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(156, 199, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(92, 104, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(251, 144, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(58, 65, 3)\n",
      "3 3\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(64, 83, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(106, 107, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(75, 82, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(76, 101, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(144, 141, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(63, 124, 3)\n",
      "0 1\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(54, 75, 3)\n",
      "5 5\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(29, 28, 3)\n",
      "17 18\n",
      "18 18\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(84, 61, 3)\n",
      "0 0\n",
      "1 2\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(187, 197, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(92, 121, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(68, 85, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(132, 95, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(67, 77, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(161, 135, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(154, 139, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(53, 89, 3)\n",
      "5 6\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(58, 61, 3)\n",
      "3 3\n",
      "1 2\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(137, 105, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(72, 59, 3)\n",
      "0 0\n",
      "2 3\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(221, 253, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(62, 52, 3)\n",
      "1 1\n",
      "6 6\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(95, 90, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(79, 68, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(117, 150, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(124, 195, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(260, 202, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n",
      "(114, 205, 3)\n",
      "0 0\n",
      "0 0\n",
      "(1, 3, 64, 64)\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Extracting Labels\n",
    "df=pd.read_csv(r\"C:\\Users\\AJain7\\OneDrive - Stryker\\Personal\\Projects\\Satellite Project\\Labels\\VillageLabels_MSW.csv\")\n",
    "village_code=df[\"Town/Village\"].values\n",
    "emp_label=df[\"Village_HHD_Cluster_MSW\"].values\n",
    "actual_labels= [ int(c) for c in emp_label]\n",
    "s1 = pd.Series(actual_labels,index=list(village_code))\n",
    "\n",
    "def slice_x(img,resize_dim_x):\n",
    "    x,y,_ = img.shape\n",
    "    startx = x//2-(resize_dim_x//2)\n",
    "    return img[startx:startx+resize_dim_x, :,:]\n",
    "\n",
    "def slice_y(img,resize_dim_y):\n",
    "    x,y,_ = img.shape\n",
    "    starty = y//2-(resize_dim_y//2)\n",
    "    return img[:,starty:starty+resize_dim_y,:]\n",
    "\n",
    "def crop_center(img,cropx,cropy): #Function for cropping the image from the center\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)\n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "all_img = []\n",
    "all_label = np.array([])\n",
    "resizeDim = 64\n",
    "nchannels = 3\n",
    "path = r\"C:\\Users\\AJain7\\Downloads\\sat_images\"\n",
    "for file in os.listdir(path):\n",
    "    filename = os.path.join(path,file)\n",
    "    dataset = rasterio.open(filename)\n",
    "    village_code = int(file.split('@')[3].split('.')[0])\n",
    "    label = s1.loc[village_code]\n",
    "    all_label = np.append(all_label,label)\n",
    "    \n",
    "    #X=np.array([]).reshape((0,resizeDim,resizeDim, nchannels))\n",
    "    band1 = dataset.read(1)\n",
    "    band2 = dataset.read(2)\n",
    "    band3 = dataset.read(3)\n",
    "    band4 = dataset.read(4)\n",
    "    band5 = dataset.read(5)\n",
    "    band6 = dataset.read(6)\n",
    "    band7 = dataset.read(7)\n",
    "    band8 = dataset.read(8)\n",
    "    band9 = dataset.read(9)\n",
    "    band10 = dataset.read(10)\n",
    "    band11 = dataset.read(11)\n",
    "    band12 = dataset.read(12)\n",
    "    band13 = dataset.read(13)\n",
    "    #cd = np.dstack((band1, band2, band3, band4, band5, band6, band7, band8, band9, band10, band11, band12, band13))\n",
    "    cd = np.dstack((band1, band2, band3))\n",
    "    print(cd.shape)\n",
    "    \n",
    "    if (cd.shape[0] > resizeDim or cd.shape[1] > resizeDim):\n",
    "        #print('shape before slicing',cd.shape)\n",
    "        #print('slicing x')\n",
    "        if(cd.shape[0] > resizeDim and cd.shape[1] > resizeDim):\n",
    "            #print('Slicing both together')\n",
    "            combinedData = slice_x(cd,resize_dim_x=resizeDim)\n",
    "            combinedData = slice_y(combinedData, resize_dim_y=resizeDim)\n",
    "            #print('shape after slicing',combinedData.shape)\n",
    "            #print('FOCUS HERE--------------------------------------------------------------')\n",
    "        elif(cd.shape[0] > resizeDim and cd.shape[1] <= resizeDim):\n",
    "            #print('Slicing x')\n",
    "            combinedData = slice_x(cd,resize_dim_x=resizeDim)\n",
    "            #print('shape after slicing',combinedData.shape)\n",
    "            #print('FOCUS HERE--------------------------------------------------------------')\n",
    "        elif(cd.shape[0] <= resizeDim and cd.shape[1] > resizeDim):\n",
    "            #print('slicing y')\n",
    "            combinedData = slice_y(cd, resize_dim_y=resizeDim)\n",
    "            #print('shape after slicing',combinedData.shape)\n",
    "            #print('FOCUS HERE--------------------------------------------------------------')\n",
    "    else:\n",
    "        combinedData = cd\n",
    "        #print('Shape without slicing', combinedData.shape)\n",
    "    \n",
    "    left = (resizeDim-combinedData.shape[0])//2\n",
    "    right = resizeDim-combinedData.shape[0] - left\n",
    "    print(left, right)\n",
    "    up = (resizeDim-combinedData.shape[1])//2\n",
    "    down = resizeDim-combinedData.shape[1] - up\n",
    "    print(up, down)\n",
    "    \n",
    "    \n",
    "    data = np.lib.pad(combinedData, [(left,right),(up,down),(0,0)], 'constant')\n",
    "    #print('Before Shaping',data.shape)\n",
    "    data = np.reshape(data,(1,nchannels,resizeDim,resizeDim))\n",
    "    print(data.shape)\n",
    "    print('-------------------------------------------------')\n",
    "    #print('After Shaping',data.shape)\n",
    "    #print('  ')\n",
    "    all_img.append(data)\n",
    "ai = np.vstack(all_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
