{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ResNet Model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Changing last layer\n",
    "num_final_in = model.fc.in_features\n",
    "\n",
    "# The final layer of the model is model.fc so we can basically just overwrite it \n",
    "# to have the output = number of classes we need. Say, 300 classes.\n",
    "NUM_CLASSES = 3\n",
    "model.fc = nn.Linear(num_final_in, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get old weights\n",
    "old_conv_weight = model.conv1.weight.data\n",
    "#print(type(old_conv_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new conv layer (10 layer and not 13)\n",
    "# Landsat 7 -> 8 bands\n",
    "# Landsat 8 -> 9 bands\n",
    "new_conv = nn.Conv2d(9, 64, kernel_size=7, stride=2, padding=3, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0284,  0.0123,  0.0176,  ...,  0.0137, -0.0295, -0.0438],\n",
       "          [ 0.0151,  0.0199,  0.0178,  ...,  0.0295,  0.0203, -0.0162],\n",
       "          [ 0.0083,  0.0109, -0.0016,  ..., -0.0510,  0.0123, -0.0082],\n",
       "          ...,\n",
       "          [-0.0062,  0.0471,  0.0069,  ...,  0.0075,  0.0380,  0.0028],\n",
       "          [-0.0182, -0.0113, -0.0160,  ..., -0.0085,  0.0150, -0.0171],\n",
       "          [-0.0417, -0.0018, -0.0074,  ..., -0.0011,  0.0098,  0.0100]],\n",
       "\n",
       "         [[-0.0205,  0.0115, -0.0086,  ..., -0.0110, -0.0215, -0.0027],\n",
       "          [-0.0003,  0.0074,  0.0069,  ..., -0.0192, -0.0155, -0.0377],\n",
       "          [ 0.0200, -0.0612, -0.0110,  ...,  0.0072,  0.0004,  0.0024],\n",
       "          ...,\n",
       "          [ 0.0133,  0.0427,  0.0246,  ...,  0.0110, -0.0110, -0.0028],\n",
       "          [ 0.0148, -0.0005,  0.0103,  ...,  0.0305,  0.0001, -0.0050],\n",
       "          [-0.0213, -0.0101,  0.0248,  ...,  0.0083, -0.0015,  0.0137]],\n",
       "\n",
       "         [[-0.0313, -0.0174,  0.0068,  ..., -0.0181, -0.0429,  0.0378],\n",
       "          [ 0.0042,  0.0198, -0.0056,  ..., -0.0181, -0.0054, -0.0025],\n",
       "          [-0.0187,  0.0029, -0.0080,  ...,  0.0245, -0.0008,  0.0001],\n",
       "          ...,\n",
       "          [-0.0196, -0.0535, -0.0049,  ..., -0.0188, -0.0204,  0.0735],\n",
       "          [-0.0022, -0.0044, -0.0094,  ..., -0.0155, -0.0137, -0.0092],\n",
       "          [ 0.0045,  0.0539,  0.0168,  ...,  0.0011,  0.0068,  0.0015]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0097, -0.0163, -0.0799,  ...,  0.0240, -0.0299,  0.0068],\n",
       "          [-0.0163, -0.0330,  0.0209,  ..., -0.0121,  0.0266, -0.0058],\n",
       "          [-0.0233, -0.0410, -0.0232,  ..., -0.0029,  0.0078,  0.0065],\n",
       "          ...,\n",
       "          [ 0.0007, -0.0068,  0.0031,  ..., -0.0064, -0.0063, -0.0364],\n",
       "          [-0.0338,  0.0047, -0.0078,  ..., -0.0118, -0.0191, -0.0410],\n",
       "          [-0.0154,  0.0053,  0.0272,  ..., -0.0240, -0.0090,  0.0192]],\n",
       "\n",
       "         [[-0.0169, -0.0054,  0.0463,  ...,  0.0294, -0.0131,  0.0083],\n",
       "          [-0.0249, -0.0153,  0.0249,  ..., -0.0257, -0.0204, -0.0210],\n",
       "          [ 0.0039,  0.0007, -0.0190,  ...,  0.0120,  0.0104, -0.0037],\n",
       "          ...,\n",
       "          [ 0.0206, -0.0003,  0.0085,  ..., -0.0276, -0.0279,  0.0348],\n",
       "          [ 0.0584,  0.0430, -0.0248,  ..., -0.0106,  0.0013, -0.0010],\n",
       "          [ 0.0193, -0.0241, -0.0385,  ..., -0.0239,  0.0335, -0.0032]],\n",
       "\n",
       "         [[ 0.0113, -0.0012,  0.0077,  ...,  0.0157, -0.0023, -0.0107],\n",
       "          [-0.0241,  0.0107,  0.0232,  ..., -0.0221,  0.0101,  0.0009],\n",
       "          [-0.0196,  0.0012,  0.0051,  ..., -0.0264, -0.0141, -0.0084],\n",
       "          ...,\n",
       "          [ 0.0321, -0.0452, -0.0035,  ..., -0.0455,  0.0427,  0.0080],\n",
       "          [-0.0134, -0.0068,  0.0156,  ..., -0.0716,  0.0403,  0.0239],\n",
       "          [ 0.0100,  0.0280,  0.0220,  ..., -0.0004, -0.0448,  0.0124]]],\n",
       "\n",
       "\n",
       "        [[[-0.0077, -0.0079,  0.0368,  ..., -0.0318,  0.0209,  0.0416],\n",
       "          [ 0.0239,  0.0289,  0.0602,  ...,  0.0215,  0.0355, -0.0120],\n",
       "          [ 0.0319,  0.0156,  0.0069,  ..., -0.0154, -0.0050, -0.0486],\n",
       "          ...,\n",
       "          [-0.0069, -0.0022, -0.0206,  ..., -0.0028, -0.0414,  0.0177],\n",
       "          [ 0.0606, -0.0127,  0.0102,  ...,  0.0131,  0.0214, -0.0193],\n",
       "          [-0.0043, -0.0098,  0.0198,  ..., -0.0135, -0.0109,  0.0035]],\n",
       "\n",
       "         [[-0.0789,  0.0007,  0.0133,  ..., -0.0089, -0.0483,  0.0022],\n",
       "          [-0.0484, -0.0241, -0.0106,  ..., -0.0115,  0.0323, -0.0055],\n",
       "          [-0.0016,  0.0095,  0.0188,  ...,  0.0000, -0.0050, -0.0070],\n",
       "          ...,\n",
       "          [-0.0208, -0.0044, -0.0187,  ..., -0.0578, -0.0459, -0.0093],\n",
       "          [-0.0293,  0.0237,  0.0337,  ..., -0.0231, -0.0142,  0.0192],\n",
       "          [-0.0392, -0.0074, -0.0100,  ...,  0.0079,  0.0182, -0.0404]],\n",
       "\n",
       "         [[ 0.0238,  0.0312, -0.0172,  ..., -0.0421,  0.0141, -0.0039],\n",
       "          [-0.0040, -0.0059,  0.0113,  ..., -0.0371, -0.0093,  0.0475],\n",
       "          [-0.0030,  0.0041, -0.0317,  ...,  0.0074, -0.0071, -0.0162],\n",
       "          ...,\n",
       "          [ 0.0143, -0.0082, -0.0423,  ...,  0.0142,  0.0402, -0.0421],\n",
       "          [ 0.0076, -0.0020, -0.0515,  ...,  0.0091,  0.0132, -0.0278],\n",
       "          [ 0.0290,  0.0096, -0.0042,  ..., -0.0315, -0.0074, -0.0467]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0368, -0.0082, -0.0038,  ..., -0.0164, -0.0283,  0.0123],\n",
       "          [-0.0079,  0.0159,  0.0104,  ...,  0.0117, -0.0060, -0.0217],\n",
       "          [ 0.0269, -0.0002, -0.0363,  ..., -0.0275,  0.0033,  0.0001],\n",
       "          ...,\n",
       "          [ 0.0088,  0.0222, -0.0183,  ...,  0.0134, -0.0269, -0.0068],\n",
       "          [-0.0286,  0.0136, -0.0346,  ..., -0.0323, -0.0119, -0.0267],\n",
       "          [-0.0281, -0.0070, -0.0299,  ..., -0.0041, -0.0171, -0.0379]],\n",
       "\n",
       "         [[-0.0151,  0.0006, -0.0332,  ..., -0.0320,  0.0040, -0.0112],\n",
       "          [-0.0084,  0.0202, -0.0355,  ...,  0.0020,  0.0068, -0.0312],\n",
       "          [-0.0407, -0.0112, -0.0675,  ...,  0.0192, -0.0160,  0.0384],\n",
       "          ...,\n",
       "          [ 0.0032,  0.0366, -0.0054,  ...,  0.0435,  0.0420, -0.0221],\n",
       "          [-0.0088, -0.0173, -0.0010,  ...,  0.0058,  0.0124, -0.0353],\n",
       "          [ 0.0026,  0.0273, -0.0014,  ...,  0.0198,  0.0235,  0.0032]],\n",
       "\n",
       "         [[ 0.0094, -0.0250, -0.0275,  ...,  0.0247, -0.0314, -0.0005],\n",
       "          [ 0.0198, -0.0061,  0.0133,  ..., -0.0099, -0.0053, -0.0143],\n",
       "          [-0.0476,  0.0090, -0.0004,  ..., -0.0227,  0.0135,  0.0008],\n",
       "          ...,\n",
       "          [ 0.0075, -0.0196,  0.0129,  ..., -0.0181, -0.0159,  0.0007],\n",
       "          [ 0.0009, -0.0031,  0.0204,  ...,  0.0302, -0.0438, -0.0280],\n",
       "          [-0.0276,  0.0028, -0.0067,  ...,  0.0030, -0.0219,  0.0242]]],\n",
       "\n",
       "\n",
       "        [[[-0.0183,  0.0111,  0.0022,  ...,  0.0136,  0.0027,  0.0215],\n",
       "          [ 0.0568, -0.0149,  0.0275,  ...,  0.0210,  0.0040, -0.0161],\n",
       "          [-0.0177, -0.0530,  0.0087,  ..., -0.0017, -0.0114, -0.0248],\n",
       "          ...,\n",
       "          [ 0.0415, -0.0241,  0.0140,  ..., -0.0038,  0.0391, -0.0024],\n",
       "          [-0.0078,  0.0255,  0.0175,  ...,  0.0021,  0.0029,  0.0175],\n",
       "          [ 0.0099, -0.0109, -0.0194,  ...,  0.0128, -0.0336,  0.0161]],\n",
       "\n",
       "         [[ 0.0016, -0.0291,  0.0047,  ...,  0.0055,  0.0071,  0.0031],\n",
       "          [ 0.0084, -0.0195, -0.0161,  ..., -0.0066, -0.0251,  0.0224],\n",
       "          [-0.0378, -0.0052,  0.0097,  ...,  0.0022, -0.0184, -0.0351],\n",
       "          ...,\n",
       "          [ 0.0283,  0.0059,  0.0105,  ..., -0.0033,  0.0446, -0.0088],\n",
       "          [-0.0229, -0.0268,  0.0313,  ...,  0.0068, -0.0241, -0.0215],\n",
       "          [-0.0432, -0.0179, -0.0399,  ..., -0.0542,  0.0289, -0.0072]],\n",
       "\n",
       "         [[-0.0133,  0.0066,  0.0103,  ...,  0.0360,  0.0021,  0.0339],\n",
       "          [ 0.0072, -0.0153, -0.0224,  ...,  0.0344, -0.0437, -0.0066],\n",
       "          [-0.0031, -0.0051, -0.0086,  ..., -0.0032,  0.0209,  0.0020],\n",
       "          ...,\n",
       "          [-0.0375,  0.0011,  0.0048,  ..., -0.0038,  0.0460, -0.0135],\n",
       "          [-0.0146, -0.0021, -0.0179,  ..., -0.0263, -0.0086,  0.0444],\n",
       "          [ 0.0234, -0.0171,  0.0230,  ..., -0.0317, -0.0255,  0.0030]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0198, -0.0370,  0.0051,  ...,  0.0264, -0.0296,  0.0335],\n",
       "          [-0.0161,  0.0216, -0.0316,  ..., -0.0416, -0.0081,  0.0246],\n",
       "          [ 0.0298,  0.0257,  0.0158,  ..., -0.0272, -0.0025, -0.0194],\n",
       "          ...,\n",
       "          [ 0.0262, -0.0327,  0.0040,  ..., -0.0163,  0.0114,  0.0259],\n",
       "          [ 0.0273,  0.0183,  0.0026,  ...,  0.0279,  0.0635, -0.0394],\n",
       "          [-0.0075,  0.0065,  0.0002,  ..., -0.0088,  0.0274,  0.0070]],\n",
       "\n",
       "         [[-0.0022,  0.0265, -0.0204,  ..., -0.0098, -0.0274,  0.0164],\n",
       "          [ 0.0412,  0.0474, -0.0246,  ...,  0.0115,  0.0262, -0.0109],\n",
       "          [-0.0295, -0.0181,  0.0204,  ...,  0.0199, -0.0270, -0.0739],\n",
       "          ...,\n",
       "          [ 0.0030,  0.0113,  0.0379,  ...,  0.0089, -0.0017, -0.0016],\n",
       "          [ 0.0130, -0.0095,  0.0078,  ..., -0.0206,  0.0027,  0.0008],\n",
       "          [ 0.0477, -0.0122, -0.0092,  ..., -0.0251,  0.0546, -0.0138]],\n",
       "\n",
       "         [[-0.0241,  0.0405,  0.0288,  ...,  0.0064, -0.0113, -0.0227],\n",
       "          [ 0.0170, -0.0095,  0.0118,  ..., -0.0120, -0.0135, -0.0196],\n",
       "          [-0.0293, -0.0183, -0.0110,  ...,  0.0251, -0.0087,  0.0190],\n",
       "          ...,\n",
       "          [-0.0027, -0.0029,  0.0268,  ...,  0.0585,  0.0252, -0.0255],\n",
       "          [ 0.0157, -0.0132,  0.0200,  ...,  0.0008,  0.0390,  0.0226],\n",
       "          [-0.0087, -0.0321,  0.0599,  ..., -0.0054, -0.0042,  0.0226]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0089,  0.0521,  0.0149,  ...,  0.0201,  0.0184,  0.0027],\n",
       "          [-0.0156, -0.0033, -0.0091,  ...,  0.0023, -0.0402,  0.0092],\n",
       "          [ 0.0148, -0.0093, -0.0110,  ...,  0.0368,  0.0062,  0.0050],\n",
       "          ...,\n",
       "          [-0.0438,  0.0233,  0.0596,  ...,  0.0388,  0.0119,  0.0254],\n",
       "          [ 0.0177,  0.0102,  0.0189,  ..., -0.0185,  0.0185, -0.0089],\n",
       "          [-0.0159, -0.0073, -0.0051,  ...,  0.0059, -0.0123, -0.0219]],\n",
       "\n",
       "         [[ 0.0207,  0.0065,  0.0042,  ...,  0.0147, -0.0080, -0.0283],\n",
       "          [ 0.0029,  0.0345, -0.0051,  ..., -0.0052, -0.0127,  0.0354],\n",
       "          [-0.0386, -0.0203, -0.0361,  ...,  0.0268, -0.0214, -0.0120],\n",
       "          ...,\n",
       "          [ 0.0268, -0.0007, -0.0492,  ..., -0.0269, -0.0133,  0.0238],\n",
       "          [ 0.0119, -0.0146, -0.0094,  ..., -0.0397,  0.0335, -0.0217],\n",
       "          [ 0.0609, -0.0243,  0.0358,  ..., -0.0259,  0.0335, -0.0162]],\n",
       "\n",
       "         [[-0.0302, -0.0015, -0.0192,  ..., -0.0077,  0.0243, -0.0081],\n",
       "          [ 0.0119, -0.0046,  0.0010,  ...,  0.0162, -0.0388, -0.0202],\n",
       "          [ 0.0208, -0.0080, -0.0342,  ..., -0.0123, -0.0456, -0.0278],\n",
       "          ...,\n",
       "          [-0.0535, -0.0404,  0.0369,  ...,  0.0233,  0.0241,  0.0035],\n",
       "          [-0.0024, -0.0050, -0.0076,  ..., -0.0057, -0.0535,  0.0209],\n",
       "          [-0.0013,  0.0016,  0.0201,  ...,  0.0061, -0.0068,  0.0202]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0180, -0.0274, -0.0330,  ..., -0.0343, -0.0043,  0.0012],\n",
       "          [ 0.0126, -0.0059, -0.0230,  ..., -0.0084,  0.0239,  0.0131],\n",
       "          [ 0.0329,  0.0044,  0.0083,  ...,  0.0174,  0.0049,  0.0007],\n",
       "          ...,\n",
       "          [-0.0273,  0.0367,  0.0055,  ..., -0.0374,  0.0675,  0.0016],\n",
       "          [-0.0229, -0.0055, -0.0275,  ..., -0.0263,  0.0085, -0.0362],\n",
       "          [ 0.0089,  0.0058,  0.0088,  ..., -0.0159,  0.0205, -0.0023]],\n",
       "\n",
       "         [[-0.0142, -0.0403, -0.0344,  ..., -0.0194, -0.0141,  0.0006],\n",
       "          [-0.0002,  0.0109,  0.0258,  ...,  0.0208,  0.0253,  0.0053],\n",
       "          [ 0.0204, -0.0288, -0.0216,  ..., -0.0530, -0.0173, -0.0319],\n",
       "          ...,\n",
       "          [ 0.0200,  0.0382, -0.0224,  ..., -0.0271,  0.0033,  0.0003],\n",
       "          [-0.0030,  0.0315, -0.0462,  ..., -0.0072,  0.0111,  0.0002],\n",
       "          [-0.0210,  0.0443, -0.0262,  ...,  0.0304, -0.0056,  0.0207]],\n",
       "\n",
       "         [[ 0.0128,  0.0261,  0.0523,  ...,  0.0149,  0.0032, -0.0382],\n",
       "          [ 0.0032,  0.0096,  0.0114,  ..., -0.0320, -0.0297, -0.0111],\n",
       "          [ 0.0177,  0.0064, -0.0054,  ..., -0.0297,  0.0019,  0.0046],\n",
       "          ...,\n",
       "          [-0.0218, -0.0085,  0.0285,  ...,  0.0129, -0.0062, -0.0004],\n",
       "          [ 0.0179,  0.0203, -0.0072,  ..., -0.0154,  0.0210, -0.0525],\n",
       "          [-0.0021,  0.0164, -0.0443,  ...,  0.0021, -0.0077, -0.0226]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0016, -0.0056,  0.0062,  ...,  0.0192,  0.0041,  0.0127],\n",
       "          [-0.0092, -0.0209,  0.0172,  ...,  0.0070,  0.0207, -0.0326],\n",
       "          [ 0.0321,  0.0075, -0.0357,  ..., -0.0341,  0.0249,  0.0035],\n",
       "          ...,\n",
       "          [ 0.0382,  0.0214, -0.0086,  ...,  0.0064,  0.0202,  0.0013],\n",
       "          [-0.0110,  0.0090, -0.0168,  ...,  0.0093, -0.0136,  0.0085],\n",
       "          [-0.0504,  0.0005,  0.0290,  ..., -0.0063, -0.0118,  0.0073]],\n",
       "\n",
       "         [[-0.0083,  0.0043, -0.0479,  ..., -0.0141,  0.0149, -0.0350],\n",
       "          [-0.0051,  0.0045,  0.0349,  ..., -0.0115,  0.0227, -0.0680],\n",
       "          [ 0.0193,  0.0046,  0.0111,  ..., -0.0180, -0.0082, -0.0267],\n",
       "          ...,\n",
       "          [ 0.0302, -0.0093,  0.0189,  ...,  0.0042, -0.0203,  0.0091],\n",
       "          [ 0.0369, -0.0485,  0.0242,  ..., -0.0586,  0.0061,  0.0242],\n",
       "          [ 0.0383, -0.0071,  0.0065,  ...,  0.0209, -0.0170,  0.0318]],\n",
       "\n",
       "         [[ 0.0008,  0.0402,  0.0285,  ...,  0.0205, -0.0196,  0.0149],\n",
       "          [-0.0048,  0.0231,  0.0153,  ...,  0.0010, -0.0207, -0.0311],\n",
       "          [-0.0119, -0.0478,  0.0069,  ..., -0.0236, -0.0562, -0.0131],\n",
       "          ...,\n",
       "          [-0.0326,  0.0311,  0.0167,  ..., -0.0135,  0.0112,  0.0239],\n",
       "          [ 0.0526, -0.0437, -0.0406,  ...,  0.0090, -0.0472, -0.0046],\n",
       "          [-0.0711,  0.0063,  0.0116,  ...,  0.0078, -0.0376,  0.0140]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0079, -0.0127,  0.0112,  ...,  0.0011, -0.0136, -0.0106],\n",
       "          [-0.0005, -0.0006, -0.0148,  ..., -0.0206, -0.0006,  0.0344],\n",
       "          [ 0.0006, -0.0165,  0.0027,  ..., -0.0083,  0.0165, -0.0164],\n",
       "          ...,\n",
       "          [ 0.0114,  0.0340,  0.0291,  ...,  0.0161, -0.0164, -0.0006],\n",
       "          [-0.0063,  0.0064, -0.0001,  ...,  0.0313,  0.0008,  0.0010],\n",
       "          [-0.0041,  0.0019, -0.0034,  ...,  0.0110,  0.0489,  0.0061]],\n",
       "\n",
       "         [[-0.0033,  0.0259, -0.0474,  ..., -0.0038,  0.0067,  0.0194],\n",
       "          [ 0.0046,  0.0075,  0.0150,  ...,  0.0088, -0.0001,  0.0404],\n",
       "          [-0.0473, -0.0224,  0.0264,  ...,  0.0128, -0.0150,  0.0171],\n",
       "          ...,\n",
       "          [ 0.0015,  0.0068, -0.0166,  ..., -0.0231, -0.0219, -0.0490],\n",
       "          [ 0.0223, -0.0175, -0.0018,  ..., -0.0126,  0.0002, -0.0033],\n",
       "          [-0.0013, -0.0201, -0.0127,  ...,  0.0202,  0.0016,  0.0450]],\n",
       "\n",
       "         [[-0.0121,  0.0022, -0.0336,  ..., -0.0384, -0.0220, -0.0113],\n",
       "          [ 0.0255, -0.0061, -0.0282,  ..., -0.0111,  0.0227, -0.0288],\n",
       "          [ 0.0088, -0.0284, -0.0037,  ..., -0.0014,  0.0040, -0.0179],\n",
       "          ...,\n",
       "          [-0.0038,  0.0207, -0.0441,  ..., -0.0036, -0.0042,  0.0166],\n",
       "          [-0.0195, -0.0083, -0.0019,  ..., -0.0286, -0.0293, -0.0163],\n",
       "          [ 0.0135,  0.0246,  0.0031,  ...,  0.0033, -0.0103,  0.0001]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0258, -0.0108,  0.0008,  ...,  0.0138, -0.0227,  0.0160],\n",
       "          [ 0.0072, -0.0130,  0.0077,  ...,  0.0080, -0.0068,  0.0073],\n",
       "          [ 0.0166,  0.0306,  0.0076,  ...,  0.0586, -0.0087,  0.0174],\n",
       "          ...,\n",
       "          [ 0.0369, -0.0247, -0.0155,  ..., -0.0303,  0.0065, -0.0123],\n",
       "          [-0.0284,  0.0314, -0.0595,  ...,  0.0276,  0.0244,  0.0245],\n",
       "          [ 0.0177,  0.0171,  0.0049,  ..., -0.0059, -0.0014, -0.0060]],\n",
       "\n",
       "         [[ 0.0242, -0.0010,  0.0167,  ..., -0.0148,  0.0155, -0.0272],\n",
       "          [-0.0252, -0.0039,  0.0254,  ..., -0.0079,  0.0184, -0.0173],\n",
       "          [-0.0478,  0.0170,  0.0154,  ...,  0.0010, -0.0117,  0.0104],\n",
       "          ...,\n",
       "          [-0.0439,  0.0065,  0.0293,  ..., -0.0296, -0.0018,  0.0016],\n",
       "          [ 0.0042, -0.0098, -0.0272,  ..., -0.0072,  0.0391,  0.0180],\n",
       "          [-0.0059, -0.0187,  0.0272,  ...,  0.0441, -0.0120,  0.0546]],\n",
       "\n",
       "         [[-0.0027,  0.0347, -0.0199,  ...,  0.0235,  0.0025,  0.0169],\n",
       "          [ 0.0321,  0.0042,  0.0162,  ..., -0.0062, -0.0218, -0.0201],\n",
       "          [ 0.0002,  0.0554,  0.0485,  ...,  0.0217, -0.0124, -0.0033],\n",
       "          ...,\n",
       "          [ 0.0655, -0.0252,  0.0172,  ..., -0.0176, -0.0312, -0.0043],\n",
       "          [ 0.0303,  0.0064, -0.0552,  ...,  0.0600,  0.0318, -0.0346],\n",
       "          [ 0.0299, -0.0006,  0.0326,  ..., -0.0321,  0.0170,  0.0130]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0088, -0.0044, -0.0086,  ..., -0.0019,  0.0331, -0.0043],\n",
       "          [ 0.0286,  0.0240,  0.0328,  ...,  0.0024, -0.0216,  0.0147],\n",
       "          [-0.0155, -0.0316,  0.0041,  ..., -0.0271,  0.0137, -0.0046],\n",
       "          ...,\n",
       "          [-0.0025,  0.0124, -0.0069,  ..., -0.0133, -0.0016, -0.0134],\n",
       "          [-0.0240, -0.0251, -0.0032,  ...,  0.0007,  0.0116, -0.0406],\n",
       "          [-0.0298, -0.0109,  0.0046,  ...,  0.0123,  0.0001, -0.0174]],\n",
       "\n",
       "         [[ 0.0195,  0.0550, -0.0075,  ..., -0.0113, -0.0402,  0.0151],\n",
       "          [ 0.0279, -0.0032, -0.0170,  ..., -0.0394, -0.0536, -0.0104],\n",
       "          [-0.0146, -0.0181, -0.0219,  ...,  0.0286,  0.0001,  0.0078],\n",
       "          ...,\n",
       "          [ 0.0147, -0.0218,  0.0129,  ..., -0.0104,  0.0153, -0.0320],\n",
       "          [ 0.0187, -0.0207,  0.0119,  ..., -0.0023,  0.0030, -0.0114],\n",
       "          [ 0.0094,  0.0186, -0.0087,  ...,  0.0406, -0.0019,  0.0083]],\n",
       "\n",
       "         [[-0.0174,  0.0182,  0.0487,  ..., -0.0422,  0.0600,  0.0114],\n",
       "          [ 0.0042,  0.0091, -0.0303,  ..., -0.0136,  0.0315,  0.0275],\n",
       "          [ 0.0206,  0.0013,  0.0333,  ...,  0.0105, -0.0074,  0.0100],\n",
       "          ...,\n",
       "          [ 0.0195,  0.0001,  0.0063,  ...,  0.0027,  0.0017, -0.0086],\n",
       "          [ 0.0183, -0.0360, -0.0305,  ...,  0.0063, -0.0036, -0.0205],\n",
       "          [ 0.0127,  0.0402,  0.0084,  ..., -0.0220,  0.0101,  0.0084]]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xavier init\n",
    "nn.init.xavier_normal_(new_conv.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,\n",
       "            1.7083e-02, -1.2694e-02],\n",
       "          [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,\n",
       "           -1.2907e-01,  3.7424e-03],\n",
       "          [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,\n",
       "            2.5632e-01,  6.3573e-02],\n",
       "          ...,\n",
       "          [-2.7535e-02,  1.6045e-02,  7.2595e-02,  ..., -3.3285e-01,\n",
       "           -4.2058e-01, -2.5781e-01],\n",
       "          [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  ...,  4.1384e-01,\n",
       "            3.9359e-01,  1.6606e-01],\n",
       "          [-1.3736e-02, -3.6746e-03, -2.4084e-02,  ..., -1.5070e-01,\n",
       "           -8.2230e-02, -5.7828e-03]],\n",
       "\n",
       "         [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  ...,  3.2521e-02,\n",
       "            6.6221e-04, -2.5743e-02],\n",
       "          [ 4.5687e-02,  3.3603e-02, -1.0453e-01,  ..., -3.1253e-01,\n",
       "           -1.6051e-01, -1.2826e-03],\n",
       "          [-8.3730e-04,  9.8420e-02,  4.0210e-01,  ...,  7.0789e-01,\n",
       "            3.6887e-01,  1.2455e-01],\n",
       "          ...,\n",
       "          [-5.5926e-02, -5.2239e-03,  2.7081e-02,  ..., -4.6178e-01,\n",
       "           -5.7080e-01, -3.6552e-01],\n",
       "          [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  ...,  5.4636e-01,\n",
       "            4.8276e-01,  1.9867e-01],\n",
       "          [ 5.3051e-03,  6.6938e-03, -1.7254e-02,  ..., -1.4822e-01,\n",
       "           -7.7248e-02,  7.2183e-04]],\n",
       "\n",
       "         [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  ...,  8.9177e-02,\n",
       "            3.3655e-02, -2.0102e-02],\n",
       "          [ 1.5398e-02, -1.8648e-02, -1.2591e-01,  ..., -2.5342e-01,\n",
       "           -1.2980e-01, -2.7975e-02],\n",
       "          [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  ...,  3.4872e-01,\n",
       "            1.0433e-01,  1.8413e-02],\n",
       "          ...,\n",
       "          [-2.8356e-02,  1.8404e-02,  9.8647e-02,  ..., -1.1740e-01,\n",
       "           -2.5760e-01, -1.5451e-01],\n",
       "          [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  ...,  2.4141e-01,\n",
       "            2.4345e-01,  1.1796e-01],\n",
       "          [ 7.4684e-04,  7.7677e-04, -1.0050e-02,  ..., -1.4865e-01,\n",
       "           -1.1754e-01, -3.8350e-02]]],\n",
       "\n",
       "\n",
       "        [[[-4.4154e-03, -4.0645e-03,  3.1589e-03,  ..., -3.7026e-02,\n",
       "           -2.5158e-02, -4.7945e-02],\n",
       "          [ 5.1310e-02,  5.3402e-02,  8.0436e-02,  ...,  1.4480e-01,\n",
       "            1.4287e-01,  1.2312e-01],\n",
       "          [-7.3337e-03,  2.1755e-03,  3.7580e-02,  ...,  6.1517e-02,\n",
       "            8.0324e-02,  1.1715e-01],\n",
       "          ...,\n",
       "          [-2.6754e-02, -1.2297e-01, -1.3653e-01,  ..., -1.4068e-01,\n",
       "           -1.1155e-01, -4.9556e-02],\n",
       "          [ 2.3524e-02, -1.7288e-02, -1.1122e-02,  ..., -1.8826e-02,\n",
       "           -2.3320e-02, -2.9474e-02],\n",
       "          [ 2.8689e-02,  2.1659e-02,  4.7888e-02,  ...,  2.5498e-02,\n",
       "            3.5346e-02,  1.1280e-02]],\n",
       "\n",
       "         [[ 4.6919e-04,  1.2153e-02,  4.2035e-02,  ...,  4.6403e-02,\n",
       "            4.0423e-02, -1.4439e-02],\n",
       "          [ 4.3463e-02,  6.8779e-02,  1.3268e-01,  ...,  2.8606e-01,\n",
       "            2.6905e-01,  2.0935e-01],\n",
       "          [-5.7621e-02, -2.2642e-02,  3.0547e-02,  ...,  1.3763e-01,\n",
       "            1.6538e-01,  1.7946e-01],\n",
       "          ...,\n",
       "          [-1.0816e-01, -2.5227e-01, -2.9742e-01,  ..., -2.8503e-01,\n",
       "           -2.1493e-01, -1.0320e-01],\n",
       "          [ 4.0709e-02, -3.2771e-02, -6.3450e-02,  ..., -9.2360e-02,\n",
       "           -6.9876e-02, -4.9841e-02],\n",
       "          [ 8.2942e-02,  8.7580e-02,  1.0111e-01,  ...,  5.2714e-02,\n",
       "            6.0968e-02,  4.1198e-02]],\n",
       "\n",
       "         [[-1.6391e-02, -1.3870e-02,  5.2810e-03,  ...,  4.3698e-02,\n",
       "            2.2707e-02, -4.5983e-02],\n",
       "          [ 3.3202e-02,  4.2014e-02,  9.3500e-02,  ...,  2.6162e-01,\n",
       "            2.2970e-01,  1.6694e-01],\n",
       "          [-4.5987e-02, -1.6365e-02,  2.6811e-02,  ...,  1.4951e-01,\n",
       "            1.3216e-01,  1.3579e-01],\n",
       "          ...,\n",
       "          [-7.2129e-02, -1.8902e-01, -2.3389e-01,  ..., -1.9038e-01,\n",
       "           -1.5609e-01, -7.5974e-02],\n",
       "          [ 5.1161e-02, -2.5815e-02, -6.9357e-02,  ..., -5.8999e-02,\n",
       "           -6.1550e-02, -4.4555e-02],\n",
       "          [ 1.1174e-01,  7.8979e-02,  6.5849e-02,  ...,  3.1617e-02,\n",
       "            2.5221e-02,  7.4257e-03]]],\n",
       "\n",
       "\n",
       "        [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
       "           -1.0905e-07, -8.3421e-08],\n",
       "          [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
       "           -4.3836e-08, -3.0538e-09],\n",
       "          [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
       "           -1.0951e-09,  4.2442e-08],\n",
       "          ...,\n",
       "          [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
       "           -4.7666e-08, -1.3265e-08],\n",
       "          [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
       "            1.0628e-07,  9.3316e-08],\n",
       "          [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
       "            1.7710e-07,  1.7166e-07]],\n",
       "\n",
       "         [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
       "           -1.3309e-07, -1.0820e-07],\n",
       "          [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
       "           -6.7022e-08, -2.2574e-08],\n",
       "          [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
       "           -7.9591e-09,  3.9750e-08],\n",
       "          ...,\n",
       "          [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
       "           -5.9930e-08, -1.8247e-08],\n",
       "          [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
       "            4.1781e-08,  4.5901e-08],\n",
       "          [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
       "            8.7550e-08,  9.8837e-08]],\n",
       "\n",
       "         [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
       "           -2.6217e-08, -1.5649e-08],\n",
       "          [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
       "            7.1450e-08,  9.7615e-08],\n",
       "          [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
       "            1.3487e-07,  1.6449e-07],\n",
       "          ...,\n",
       "          [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
       "            6.8382e-08,  1.1367e-07],\n",
       "          [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
       "            1.1723e-07,  1.4394e-07],\n",
       "          [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
       "            1.3333e-07,  1.5844e-07]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-6.1896e-02, -3.0206e-02,  1.9225e-02,  ...,  4.3665e-02,\n",
       "           -2.2114e-02, -4.2214e-02],\n",
       "          [-3.8061e-02,  6.0774e-03,  4.5797e-02,  ...,  9.6029e-02,\n",
       "            5.9254e-02,  2.9958e-02],\n",
       "          [-2.9672e-02,  2.7766e-03,  2.0457e-02,  ...,  5.9828e-02,\n",
       "            4.1422e-02,  2.3134e-02],\n",
       "          ...,\n",
       "          [ 1.1916e-02,  4.5701e-02,  4.4892e-02,  ...,  4.7419e-02,\n",
       "            2.2274e-02, -5.4993e-03],\n",
       "          [-3.2468e-02, -1.2210e-02,  2.2023e-02,  ...,  5.8061e-02,\n",
       "           -7.5033e-03, -5.9736e-02],\n",
       "          [-4.3314e-02, -2.8162e-02, -5.9126e-03,  ...,  8.8460e-02,\n",
       "            8.4406e-03, -5.0019e-02]],\n",
       "\n",
       "         [[-6.1292e-02, -1.4004e-02,  1.7229e-02,  ...,  1.8349e-02,\n",
       "           -3.2708e-02, -4.1060e-02],\n",
       "          [-3.1506e-02,  2.4460e-02,  4.5516e-02,  ...,  6.6806e-02,\n",
       "            4.6687e-02,  3.3248e-02],\n",
       "          [-3.2216e-02,  2.0718e-02,  2.3343e-02,  ...,  3.5265e-02,\n",
       "            3.6478e-02,  3.1291e-02],\n",
       "          ...,\n",
       "          [ 1.7739e-02,  6.1040e-02,  4.8247e-02,  ...,  3.7785e-02,\n",
       "            2.8894e-02,  1.3984e-02],\n",
       "          [-1.0890e-02,  2.2079e-02,  4.2737e-02,  ...,  6.0247e-02,\n",
       "            1.6197e-02, -1.2493e-02],\n",
       "          [-2.2284e-02,  1.3220e-02,  3.0897e-02,  ...,  1.0403e-01,\n",
       "            4.0119e-02, -5.3310e-03]],\n",
       "\n",
       "         [[-8.5322e-02, -4.2603e-02,  6.8145e-03,  ...,  3.0751e-02,\n",
       "           -3.4818e-02, -4.9945e-02],\n",
       "          [-2.9215e-02,  1.8165e-02,  5.1092e-02,  ...,  9.0200e-02,\n",
       "            5.3438e-02,  4.0169e-02],\n",
       "          [-3.9932e-02, -1.1100e-03,  9.6176e-03,  ...,  2.4114e-02,\n",
       "            2.6298e-02,  2.5489e-02],\n",
       "          ...,\n",
       "          [-3.1890e-03,  3.0454e-02,  1.6316e-02,  ...,  5.5054e-03,\n",
       "           -6.2689e-03, -8.4638e-03],\n",
       "          [-2.2995e-02, -2.8211e-03,  2.3203e-02,  ...,  3.5888e-02,\n",
       "           -1.4296e-02, -3.2419e-02],\n",
       "          [-9.8894e-03,  7.0542e-03,  1.0659e-02,  ...,  7.0495e-02,\n",
       "            1.2996e-02, -8.3417e-03]]],\n",
       "\n",
       "\n",
       "        [[[-7.8699e-03,  1.9911e-02,  3.4208e-02,  ...,  2.8694e-02,\n",
       "            1.2820e-02,  1.8142e-02],\n",
       "          [ 8.7942e-03, -3.2875e-02, -3.5713e-02,  ...,  7.2533e-02,\n",
       "            4.5889e-02,  5.2383e-02],\n",
       "          [-3.6122e-02, -1.1878e-01, -1.3767e-01,  ...,  3.3811e-02,\n",
       "            3.7806e-02,  2.6944e-02],\n",
       "          ...,\n",
       "          [ 1.7322e-02,  3.9589e-03, -8.2269e-03,  ...,  2.7543e-03,\n",
       "            1.8313e-02,  1.6057e-02],\n",
       "          [-9.5007e-04,  1.6428e-02,  1.7156e-02,  ...,  3.3672e-03,\n",
       "            2.2857e-02,  6.5783e-04],\n",
       "          [ 6.1727e-03,  2.7145e-02,  1.4340e-02,  ...,  7.5867e-03,\n",
       "            1.8770e-02,  1.5624e-02]],\n",
       "\n",
       "         [[-1.3423e-02, -5.0696e-04,  8.0959e-03,  ..., -6.0963e-03,\n",
       "            9.2341e-03,  1.5751e-02],\n",
       "          [-1.8343e-02, -6.7982e-02, -7.0685e-02,  ...,  2.9855e-02,\n",
       "            2.6264e-02,  2.3773e-02],\n",
       "          [-5.4359e-02, -1.4663e-01, -1.6211e-01,  ...,  1.1781e-02,\n",
       "            3.2477e-02,  1.1980e-02],\n",
       "          ...,\n",
       "          [ 8.3686e-04, -1.7564e-02, -1.9535e-02,  ..., -4.1382e-03,\n",
       "            2.4658e-02,  1.2893e-02],\n",
       "          [-6.3183e-04,  1.1788e-02,  2.4810e-02,  ...,  6.1105e-03,\n",
       "            3.9210e-02,  9.6696e-03],\n",
       "          [-7.1831e-03,  6.6918e-03,  5.2723e-03,  ..., -7.6077e-03,\n",
       "            2.7253e-02,  1.7735e-02]],\n",
       "\n",
       "         [[-2.3753e-04, -4.9343e-03,  2.2991e-03,  ..., -4.7958e-02,\n",
       "           -2.6154e-02, -2.3525e-02],\n",
       "          [-3.3053e-04, -5.1502e-02, -5.9977e-02,  ..., -1.7369e-02,\n",
       "           -2.3337e-02, -3.7312e-02],\n",
       "          [-2.2674e-02, -9.9412e-02, -1.1176e-01,  ..., -1.1725e-02,\n",
       "           -8.3744e-03, -4.0615e-02],\n",
       "          ...,\n",
       "          [ 1.1437e-02, -8.0313e-03, -1.4955e-03,  ..., -3.4133e-02,\n",
       "           -8.7267e-03, -2.3526e-02],\n",
       "          [ 2.9522e-03,  6.7770e-04,  1.9933e-02,  ..., -2.2002e-02,\n",
       "            1.4814e-02, -1.4487e-02],\n",
       "          [-1.9085e-02, -2.9430e-02, -2.3284e-02,  ..., -4.8587e-02,\n",
       "           -1.3049e-02, -2.4368e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.6296e-02,  7.1996e-03,  1.9100e-02,  ...,  1.9602e-02,\n",
       "            1.4870e-02, -1.7298e-02],\n",
       "          [-1.1061e-02,  8.5665e-02,  1.2667e-01,  ...,  1.3744e-02,\n",
       "           -5.5036e-05, -3.0162e-02],\n",
       "          [ 1.1322e-01,  1.8634e-01,  5.0658e-02,  ..., -1.7333e-01,\n",
       "           -7.2041e-02, -6.2474e-02],\n",
       "          ...,\n",
       "          [-5.3062e-02, -2.5781e-01, -2.6747e-01,  ...,  2.6781e-01,\n",
       "            1.4344e-01,  5.5145e-02],\n",
       "          [-2.1009e-02, -2.9969e-02,  1.0245e-01,  ...,  2.0843e-01,\n",
       "           -4.1518e-03, -3.8118e-02],\n",
       "          [-2.2155e-02,  1.2380e-02,  8.4302e-02,  ..., -4.4992e-02,\n",
       "           -1.4687e-01, -9.0890e-02]],\n",
       "\n",
       "         [[-5.3969e-03,  3.2799e-02,  1.5486e-02,  ..., -7.7451e-03,\n",
       "            3.0229e-03,  1.1216e-03],\n",
       "          [ 6.1723e-02,  1.4899e-01,  1.4645e-01,  ..., -2.8897e-02,\n",
       "           -2.0227e-02, -9.1878e-03],\n",
       "          [ 1.6146e-01,  2.0886e-01, -2.5589e-02,  ..., -2.7278e-01,\n",
       "           -1.0735e-01, -6.2971e-02],\n",
       "          ...,\n",
       "          [-1.3723e-01, -4.0863e-01, -3.8551e-01,  ...,  4.0846e-01,\n",
       "            2.6202e-01,  1.3491e-01],\n",
       "          [-5.9388e-02, -6.1187e-02,  1.4197e-01,  ...,  3.5780e-01,\n",
       "            9.0893e-02, -1.7392e-03],\n",
       "          [ 7.8613e-03,  5.8403e-02,  1.5339e-01,  ...,  4.7045e-02,\n",
       "           -1.0095e-01, -9.7920e-02]],\n",
       "\n",
       "         [[-5.6799e-03,  1.3425e-02, -2.6461e-02,  ...,  4.4881e-03,\n",
       "            2.0666e-03,  1.3902e-02],\n",
       "          [ 6.5943e-03,  4.5181e-02,  6.0260e-02,  ...,  1.4368e-02,\n",
       "           -5.0725e-03,  4.0505e-03],\n",
       "          [ 5.5257e-02,  1.2397e-01,  4.3193e-02,  ..., -1.4486e-01,\n",
       "           -7.4489e-02, -5.7533e-02],\n",
       "          ...,\n",
       "          [-3.1513e-02, -1.6334e-01, -1.5795e-01,  ...,  2.2904e-01,\n",
       "            1.2017e-01,  7.1998e-02],\n",
       "          [-1.0456e-02, -1.1248e-03,  8.4582e-02,  ...,  1.5748e-01,\n",
       "            2.2142e-02, -1.0083e-02],\n",
       "          [-4.8639e-03, -5.0065e-03,  3.6341e-02,  ..., -2.4361e-02,\n",
       "           -7.1195e-02, -6.6788e-02]]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy old weights into first 3 channels\n",
    "new_conv.weight.data[:,:3].copy_(old_conv_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace old conv with the new one\n",
    "model.conv1 = new_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 0 ---------- Conv2d(9, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "-- 1 ---------- BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "-- 2 ---------- ReLU(inplace)\n",
      "-- 3 ---------- MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "-- 4 ---------- Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "-- 5 ---------- Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "-- 6 ---------- Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "-- 7 ---------- Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "-- 8 ---------- AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "-- 9 ---------- Linear(in_features=512, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for child in model.children():\n",
    "    #print(child)\n",
    "    print(\"--\", counter,'----------', child)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]          28,224\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "        AvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 3]           1,539\n",
      "================================================================\n",
      "Total params: 11,196,867\n",
      "Trainable params: 11,196,867\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.72\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 42.71\n",
      "Estimated Total Size (MB): 107.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (9,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom Dataset classes\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)    \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Labels\n",
    "df=pd.read_csv(r\"C:\\Users\\AJain7\\OneDrive - Stryker\\Personal\\Projects\\Satellite Project\\Village_Labels.csv\")  # --> Contain village label\n",
    "village_code=df[\"Town/Village\"].values\n",
    "emp_label=df[\"Village_HHD_Cluster_MSW\"].values\n",
    "actual_labels= [ int(c) for c in emp_label]\n",
    "s1 = pd.Series(actual_labels,index=list(village_code))\n",
    "\n",
    "def slice_x(img,resize_dim_x):\n",
    "    x,y,_ = img.shape\n",
    "    startx = x//2-(resize_dim_x//2)\n",
    "    return img[startx:startx+resize_dim_x, :,:]\n",
    "\n",
    "def slice_y(img,resize_dim_y):\n",
    "    x,y,_ = img.shape\n",
    "    starty = y//2-(resize_dim_y//2)\n",
    "    return img[:,starty:starty+resize_dim_y,:]\n",
    "\n",
    "def crop_center(img,cropx,cropy): #Function for cropping the image from the center\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)\n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "all_img = []\n",
    "all_label = np.array([])\n",
    "resizeDim = 224\n",
    "nchannels = 9\n",
    "path = r\"C:\\Users\\AJain7\\Desktop\\landsat_sample_data\\train\"  # --> Contains Satellite images\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    filename = os.path.join(path,file)\n",
    "    dataset = rasterio.open(filename)\n",
    "    village_code = int(file.split('@')[3].split('.')[0])\n",
    "    label = s1.loc[village_code]\n",
    "    all_label = np.append(all_label,label)\n",
    "    \n",
    "    #X=np.array([]).reshape((0,resizeDim,resizeDim, nchannels))\n",
    "    band1 = dataset.read(1)\n",
    "    band2 = dataset.read(2)\n",
    "    band3 = dataset.read(3)\n",
    "    band4 = dataset.read(4)\n",
    "    band5 = dataset.read(5)\n",
    "    band6 = dataset.read(6)\n",
    "    band7 = dataset.read(7)\n",
    "    band8 = dataset.read(8)\n",
    "    band9 = dataset.read(9)\n",
    "    band10 = dataset.read(10)\n",
    "    band11 = dataset.read(11)\n",
    "    band12 = dataset.read(12)\n",
    "    band13 = dataset.read(13)\n",
    "    \n",
    "    #cd = np.dstack((band1, band2, band3, band4, band5, band6, band7, band8, band9, band10, band11, band12, band13))\n",
    "    cd = np.dstack((band1, band2, band3, band4, band5, band6, band7, band8, band9))\n",
    "    #cd = np.dstack((band1, band2, band3, band4, band5, band6, band7, band8)) # Change Number of Channels Variables\n",
    "    \n",
    "    #print(cd.shape)\n",
    "    \n",
    "    if (cd.shape[0] > resizeDim or cd.shape[1] > resizeDim):\n",
    "        if(cd.shape[0] > resizeDim and cd.shape[1] > resizeDim):\n",
    "            combinedData = slice_x(cd,resize_dim_x=resizeDim)\n",
    "            combinedData = slice_y(combinedData, resize_dim_y=resizeDim)\n",
    "        elif(cd.shape[0] > resizeDim and cd.shape[1] <= resizeDim):\n",
    "            combinedData = slice_x(cd,resize_dim_x=resizeDim)\n",
    "        elif(cd.shape[0] <= resizeDim and cd.shape[1] > resizeDim):\n",
    "            combinedData = slice_y(cd, resize_dim_y=resizeDim)\n",
    "    else:\n",
    "        combinedData = cd\n",
    "    \n",
    "    left = (resizeDim-combinedData.shape[0])//2\n",
    "    right = resizeDim-combinedData.shape[0] - left\n",
    "    up = (resizeDim-combinedData.shape[1])//2\n",
    "    down = resizeDim-combinedData.shape[1] - up\n",
    "    \n",
    "    data = np.lib.pad(combinedData, [(left,right),(up,down),(0,0)], 'constant')\n",
    "    data = np.reshape(data,(1,nchannels,resizeDim,resizeDim))\n",
    "    all_img.append(data)\n",
    "\n",
    "ai = np.vstack(all_img)\n",
    "\n",
    "# ai --> All images of numpy array\n",
    "# all_label --> Corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 9, 224, 224)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 40\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(ai, all_label)\n",
    "\n",
    "print('Number of Samples:',dataset.__len__())\n",
    "print(dataset.__getitem__(9)[1])\n",
    "\n",
    "#loader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available() )\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 9, 224, 224)\n",
      "Number of Test Samples: 28\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#-------------------------------------------------Test Dataset-------------------------------------------------------------------\n",
    "all_test_img = []\n",
    "all_test_label = np.array([])\n",
    "\n",
    "test_path = r\"C:\\Users\\AJain7\\Desktop\\landsat_sample_data\\test\"\n",
    "#--------------------------------------------------------------------# --> Contains Satellite images\n",
    "for file in os.listdir(test_path):\n",
    "    filename = os.path.join(test_path,file)\n",
    "    dataset = rasterio.open(filename)\n",
    "    village_code = int(file.split('@')[3].split('.')[0])\n",
    "    label = s1.loc[village_code]\n",
    "    all_test_label = np.append(all_test_label,label)\n",
    "    #X=np.array([]).reshape((0,resizeDim,resizeDim, nchannels))\n",
    "    band1 = dataset.read(1)\n",
    "    band2 = dataset.read(2)\n",
    "    band3 = dataset.read(3)\n",
    "    band4 = dataset.read(4)\n",
    "    band5 = dataset.read(5)\n",
    "    band6 = dataset.read(6)\n",
    "    band7 = dataset.read(7)\n",
    "    band8 = dataset.read(8)\n",
    "    band9 = dataset.read(9)\n",
    "    band10 = dataset.read(10)\n",
    "    band11 = dataset.read(11)\n",
    "    band12 = dataset.read(12)\n",
    "    band13 = dataset.read(13)\n",
    "    \n",
    "    #cd = np.dstack((band1, band2, band3, band4, band5, band6, band7, band8, band9, band10, band11, band12, band13))\n",
    "    cd = np.dstack((band1, band2, band3, band4, band5, band6, band7, band8, band9))\n",
    "    #cd = np.dstack((band1, band2, band3, band4, band5, band6, band7, band8)) # Change Number of Channels Variables\n",
    "    \n",
    "    #print(cd.shape)\n",
    "    \n",
    "    if (cd.shape[0] > resizeDim or cd.shape[1] > resizeDim):\n",
    "        if(cd.shape[0] > resizeDim and cd.shape[1] > resizeDim):\n",
    "            combinedData = slice_x(cd,resize_dim_x=resizeDim)\n",
    "            combinedData = slice_y(combinedData, resize_dim_y=resizeDim)\n",
    "        elif(cd.shape[0] > resizeDim and cd.shape[1] <= resizeDim):\n",
    "            combinedData = slice_x(cd,resize_dim_x=resizeDim)\n",
    "        elif(cd.shape[0] <= resizeDim and cd.shape[1] > resizeDim):\n",
    "            combinedData = slice_y(cd, resize_dim_y=resizeDim)\n",
    "    else:\n",
    "        combinedData = cd\n",
    "    \n",
    "    left = (resizeDim-combinedData.shape[0])//2\n",
    "    right = resizeDim-combinedData.shape[0] - left\n",
    "    up = (resizeDim-combinedData.shape[1])//2\n",
    "    down = resizeDim-combinedData.shape[1] - up\n",
    "    \n",
    "    data = np.lib.pad(combinedData, [(left,right),(up,down),(0,0)], 'constant')\n",
    "    data = np.reshape(data,(1,nchannels,resizeDim,resizeDim))\n",
    "    all_test_img.append(data)\n",
    "\n",
    "ai_test = np.vstack(all_test_img)\n",
    "print(ai_test.shape)\n",
    "# ai --> All images of numpy array\n",
    "# all_label --> Corresponding labels\n",
    "test_dataset = MyDataset(ai_test, all_test_label)\n",
    "print('Number of Test Samples:',test_dataset.__len__())\n",
    "print(test_dataset.__getitem__(9)[1])\n",
    "#loader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=2, pin_memory=torch.cuda.is_available() )\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):    # Both Train and Evaluation model in this only\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        train_loss, valid_loss = [], []\n",
    "        \n",
    "        # Training Part\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        for i, (images,labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            #Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "            #print('Epoch [{}/{}],  Step [{}/{}], Training Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, 100, loss.item()))\n",
    "        \n",
    "        \n",
    "        # Evaluation Part\n",
    "        model.eval()\n",
    "        for i, (images_test, labels_test) in enumerate(test_loader):\n",
    "            images_test = images_test.to(device)\n",
    "            labels_test = labels_test.to(device)\n",
    "            \n",
    "            outputs_test = model(images_test)\n",
    "            loss_test = criterion(outputs_test, labels_test)\n",
    "            valid_loss.append(loss_test.item())\n",
    "            \n",
    "            #print('Epoch [{}/{}],  Step [{}/{}], Test Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, 100, loss_test.item()))\n",
    "            \n",
    "        print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# loss Function and Optimizer\n",
    "weights = [0.40896103511576953, 3.940446473147422, 3.3222489476849066]\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.001)\n",
    "els = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss:  0.5990207493305206 Valid Loss:  1.48911714553833\n",
      "Epoch: 1 Training Loss:  0.43453139066696167 Valid Loss:  0.2991034984588623\n",
      "Epoch: 2 Training Loss:  0.027375335805118084 Valid Loss:  0.00045503879664465785\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer_ft, els, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
