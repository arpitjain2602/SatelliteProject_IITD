{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing last layer\n",
    "num_final_in = model.fc.in_features\n",
    "\n",
    "# The final layer of the model is model.fc so we can basically just overwrite it \n",
    "# to have the output = number of classes we need. Say, 300 classes.\n",
    "NUM_CLASSES = 3\n",
    "model.fc = nn.Linear(num_final_in, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating custom Dataset classes\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)  \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "numpy_data_train = np.random.randn(1000,12,224,224)\n",
    "numpy_target_train = np.random.randint(0,3,size=(1000))\n",
    "\n",
    "dataset_train = MyDataset(numpy_data_train, numpy_target_train)\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Test dataset\n",
    "numpy_data_test = np.random.randn(100,12,224,224)\n",
    "numpy_target_test = np.random.randint(0,3,size=(100))\n",
    "\n",
    "dataset_test = MyDataset(numpy_data_test, numpy_target_test)\n",
    "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        \n",
    "        for i, (images,labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            #Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()    \n",
    "            \n",
    "            print('Epoch [{}/{}],  Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, 100, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # LOSS\n",
    "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # OPTIMIZER\n",
    "els = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)  # Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1],  Step [1/100], Loss: 1.1372\n",
      "Epoch [1/1],  Step [2/100], Loss: 1.0876\n",
      "Epoch [1/1],  Step [3/100], Loss: 1.1049\n",
      "Epoch [1/1],  Step [4/100], Loss: 1.1931\n",
      "Epoch [1/1],  Step [5/100], Loss: 1.0986\n",
      "Epoch [1/1],  Step [6/100], Loss: 1.0250\n",
      "Epoch [1/1],  Step [7/100], Loss: 1.1351\n",
      "Epoch [1/1],  Step [8/100], Loss: 1.0757\n",
      "Epoch [1/1],  Step [9/100], Loss: 1.0822\n",
      "Epoch [1/1],  Step [10/100], Loss: 1.1884\n",
      "Epoch [1/1],  Step [11/100], Loss: 1.1615\n",
      "Epoch [1/1],  Step [12/100], Loss: 1.1465\n",
      "Epoch [1/1],  Step [13/100], Loss: 1.0844\n",
      "Epoch [1/1],  Step [14/100], Loss: 1.0465\n",
      "Epoch [1/1],  Step [15/100], Loss: 1.0669\n",
      "Epoch [1/1],  Step [16/100], Loss: 1.0851\n",
      "Epoch [1/1],  Step [17/100], Loss: 1.0982\n",
      "Epoch [1/1],  Step [18/100], Loss: 1.1648\n",
      "Epoch [1/1],  Step [19/100], Loss: 1.1663\n",
      "Epoch [1/1],  Step [20/100], Loss: 1.1425\n",
      "Epoch [1/1],  Step [21/100], Loss: 1.1169\n",
      "Epoch [1/1],  Step [22/100], Loss: 1.0758\n",
      "Epoch [1/1],  Step [23/100], Loss: 1.0627\n",
      "Epoch [1/1],  Step [24/100], Loss: 1.1269\n",
      "Epoch [1/1],  Step [25/100], Loss: 1.1102\n",
      "Epoch [1/1],  Step [26/100], Loss: 1.1548\n",
      "Epoch [1/1],  Step [27/100], Loss: 1.0895\n",
      "Epoch [1/1],  Step [28/100], Loss: 1.1276\n",
      "Epoch [1/1],  Step [29/100], Loss: 1.1435\n",
      "Epoch [1/1],  Step [30/100], Loss: 1.0473\n",
      "Epoch [1/1],  Step [31/100], Loss: 1.1245\n",
      "Epoch [1/1],  Step [32/100], Loss: 1.0775\n",
      "Epoch [1/1],  Step [33/100], Loss: 1.0963\n",
      "Epoch [1/1],  Step [34/100], Loss: 1.0839\n",
      "Epoch [1/1],  Step [35/100], Loss: 1.0726\n",
      "Epoch [1/1],  Step [36/100], Loss: 1.1286\n",
      "Epoch [1/1],  Step [37/100], Loss: 1.1547\n",
      "Epoch [1/1],  Step [38/100], Loss: 1.1081\n",
      "Epoch [1/1],  Step [39/100], Loss: 1.1112\n",
      "Epoch [1/1],  Step [40/100], Loss: 1.1014\n",
      "Epoch [1/1],  Step [41/100], Loss: 1.1081\n",
      "Epoch [1/1],  Step [42/100], Loss: 1.1709\n",
      "Epoch [1/1],  Step [43/100], Loss: 1.1222\n",
      "Epoch [1/1],  Step [44/100], Loss: 1.0811\n",
      "Epoch [1/1],  Step [45/100], Loss: 1.1562\n",
      "Epoch [1/1],  Step [46/100], Loss: 1.0520\n",
      "Epoch [1/1],  Step [47/100], Loss: 1.0761\n",
      "Epoch [1/1],  Step [48/100], Loss: 1.1525\n",
      "Epoch [1/1],  Step [49/100], Loss: 1.1319\n",
      "Epoch [1/1],  Step [50/100], Loss: 1.0721\n",
      "Epoch [1/1],  Step [51/100], Loss: 1.3276\n",
      "Epoch [1/1],  Step [52/100], Loss: 1.2969\n",
      "Epoch [1/1],  Step [53/100], Loss: 1.1987\n",
      "Epoch [1/1],  Step [54/100], Loss: 1.0971\n",
      "Epoch [1/1],  Step [55/100], Loss: 1.0203\n",
      "Epoch [1/1],  Step [56/100], Loss: 1.3594\n",
      "Epoch [1/1],  Step [57/100], Loss: 1.3198\n",
      "Epoch [1/1],  Step [58/100], Loss: 1.3314\n",
      "Epoch [1/1],  Step [59/100], Loss: 1.1168\n",
      "Epoch [1/1],  Step [60/100], Loss: 1.1747\n",
      "Epoch [1/1],  Step [61/100], Loss: 1.1934\n",
      "Epoch [1/1],  Step [62/100], Loss: 1.0785\n",
      "Epoch [1/1],  Step [63/100], Loss: 1.1354\n"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optimizer_ft, els, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "def eval_model(model):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        print('Test Accuracy on 10 images: {} %'.format(100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on 10 images: 31.0 %\n"
     ]
    }
   ],
   "source": [
    "eval_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter is ----> 0 ----> torch.Size([64, 12, 7, 7])\n",
      "Counter is ----> 1 ----> torch.Size([64])\n",
      "Counter is ----> 2 ----> torch.Size([64])\n",
      "Counter is ----> 3 ----> torch.Size([64, 64, 3, 3])\n",
      "Counter is ----> 4 ----> torch.Size([64])\n",
      "Counter is ----> 5 ----> torch.Size([64])\n",
      "Counter is ----> 6 ----> torch.Size([64, 64, 3, 3])\n",
      "Counter is ----> 7 ----> torch.Size([64])\n",
      "Counter is ----> 8 ----> torch.Size([64])\n",
      "Counter is ----> 9 ----> torch.Size([64, 64, 3, 3])\n",
      "Counter is ----> 10 ----> torch.Size([64])\n",
      "Counter is ----> 11 ----> torch.Size([64])\n",
      "Counter is ----> 12 ----> torch.Size([64, 64, 3, 3])\n",
      "Counter is ----> 13 ----> torch.Size([64])\n",
      "Counter is ----> 14 ----> torch.Size([64])\n",
      "Counter is ----> 15 ----> torch.Size([128, 64, 3, 3])\n",
      "Counter is ----> 16 ----> torch.Size([128])\n",
      "Counter is ----> 17 ----> torch.Size([128])\n",
      "Counter is ----> 18 ----> torch.Size([128, 128, 3, 3])\n",
      "Counter is ----> 19 ----> torch.Size([128])\n",
      "Counter is ----> 20 ----> torch.Size([128])\n",
      "Counter is ----> 21 ----> torch.Size([128, 64, 1, 1])\n",
      "Counter is ----> 22 ----> torch.Size([128])\n",
      "Counter is ----> 23 ----> torch.Size([128])\n",
      "Counter is ----> 24 ----> torch.Size([128, 128, 3, 3])\n",
      "Counter is ----> 25 ----> torch.Size([128])\n",
      "Counter is ----> 26 ----> torch.Size([128])\n",
      "Counter is ----> 27 ----> torch.Size([128, 128, 3, 3])\n",
      "Counter is ----> 28 ----> torch.Size([128])\n",
      "Counter is ----> 29 ----> torch.Size([128])\n",
      "Counter is ----> 30 ----> torch.Size([256, 128, 3, 3])\n",
      "Counter is ----> 31 ----> torch.Size([256])\n",
      "Counter is ----> 32 ----> torch.Size([256])\n",
      "Counter is ----> 33 ----> torch.Size([256, 256, 3, 3])\n",
      "Counter is ----> 34 ----> torch.Size([256])\n",
      "Counter is ----> 35 ----> torch.Size([256])\n",
      "Counter is ----> 36 ----> torch.Size([256, 128, 1, 1])\n",
      "Counter is ----> 37 ----> torch.Size([256])\n",
      "Counter is ----> 38 ----> torch.Size([256])\n",
      "Counter is ----> 39 ----> torch.Size([256, 256, 3, 3])\n",
      "Counter is ----> 40 ----> torch.Size([256])\n",
      "Counter is ----> 41 ----> torch.Size([256])\n",
      "Counter is ----> 42 ----> torch.Size([256, 256, 3, 3])\n",
      "Counter is ----> 43 ----> torch.Size([256])\n",
      "Counter is ----> 44 ----> torch.Size([256])\n",
      "Counter is ----> 45 ----> torch.Size([512, 256, 3, 3])\n",
      "Counter is ----> 46 ----> torch.Size([512])\n",
      "Counter is ----> 47 ----> torch.Size([512])\n",
      "Counter is ----> 48 ----> torch.Size([512, 512, 3, 3])\n",
      "Counter is ----> 49 ----> torch.Size([512])\n",
      "Counter is ----> 50 ----> torch.Size([512])\n",
      "Counter is ----> 51 ----> torch.Size([512, 256, 1, 1])\n",
      "Counter is ----> 52 ----> torch.Size([512])\n",
      "Counter is ----> 53 ----> torch.Size([512])\n",
      "Counter is ----> 54 ----> torch.Size([512, 512, 3, 3])\n",
      "Counter is ----> 55 ----> torch.Size([512])\n",
      "Counter is ----> 56 ----> torch.Size([512])\n",
      "Counter is ----> 57 ----> torch.Size([512, 512, 3, 3])\n",
      "Counter is ----> 58 ----> torch.Size([512])\n",
      "Counter is ----> 59 ----> torch.Size([512])\n",
      "Counter is ----> 60 ----> torch.Size([3, 512])\n",
      "Counter is ----> 61 ----> torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Listing parameters\n",
    "\n",
    "counter = 0\n",
    "for i in model.parameters():\n",
    "    print('Counter is ---->',counter,'---->',i.shape)\n",
    "    counter = counter +1\n",
    "    #init.xavier_uniform_(i,gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
