{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Methods (as in point 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use model trained on\n",
    "    - current 2001, prediction_2003-2009, FEMP_2001, LIT_2001 to give output on 2011\n",
    "\n",
    "2. Give it input as\n",
    "    - current_2011, prediction_2011-2017 (obtained using model trained on 2011), FEMP_2011, LIT_2011 to give output on 2019\n",
    "    - current_2011, prediction_2013-2019 (obtained using model trained on 2011), FEMP_2011, LIT_2011 to give output on 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/arpitjain/anaconda3/envs/automl_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/arpitjain/anaconda3/envs/automl_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/arpitjain/anaconda3/envs/automl_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/arpitjain/anaconda3/envs/automl_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/arpitjain/anaconda3/envs/automl_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/arpitjain/anaconda3/envs/automl_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC- backward classifier jisme 2011 ke model se 2009,07,05,03,01 predicted+2011census+EMP2011+LIT2011 \n",
    "# Ye sab use krke 2001 ke labels predict kiye the.\n",
    "\n",
    "# FC- forward classifier\n",
    "# Isme 2001 wale model se 2011 predict kia tha. Using census2001+intermediate years+ emp+lit\n",
    "\n",
    "# Isi tarah humne forward classifier 2011 pr train krke 2019 predict kia tha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_f1_score  [0.8830784632692292, 0.8797370335434369, 0.8700843467438716, 0.8696449091416723, 0.8675950051710682]\n",
      "train_f1_score  [0.9101612730413775, 0.9117291760481253, 0.9108298530327632, 0.9128374577077851, 0.9134412114023387]\n"
     ]
    }
   ],
   "source": [
    "# tss = pickle.load( open(\"/Users/arpitjain/Downloads/SatPRo/mlpros/classifier_cv/Temporal_Transferability/CHH_2011_TT_FEMP&LIT_base_XGB.pkl\", 'rb'))\n",
    "tss = pickle.load( open(\"/Users/arpitjain/Downloads/SatPRo/mlpros/classifier_cv/Temporal_Transferability/FORMAL_EMP_2011_TT_Current+base_XGB.pkl\", 'rb'))\n",
    "print('val_f1_score ',tss['xgBoost']['val_scores'])\n",
    "print('train_f1_score ',tss['xgBoost']['train_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 \n",
      "Re-Training again for calculating f1 and train scores\n"
     ]
    }
   ],
   "source": [
    "n_estimators = tss['xgBoost']['specs'][0]['n_estimators']\n",
    "max_depth = tss['xgBoost']['specs'][0]['max_depth']\n",
    "learning_rate = tss['xgBoost']['specs'][0]['learning_rate']\n",
    "objective = tss['xgBoost']['specs'][0]['objective']\n",
    "booster = tss['xgBoost']['specs'][0]['booster']\n",
    "gamma = tss['xgBoost']['specs'][0]['gamma']\n",
    "min_child_weight = tss['xgBoost']['specs'][0]['min_child_weight']\n",
    "max_delta_step = tss['xgBoost']['specs'][0]['max_delta_step']\n",
    "subsample = tss['xgBoost']['specs'][0]['subsample']\n",
    "colsample_bytree = tss['xgBoost']['specs'][0]['colsample_bytree']\n",
    "colsample_bylevel = tss['xgBoost']['specs'][0]['colsample_bylevel']\n",
    "colsample_bynode = tss['xgBoost']['specs'][0]['colsample_bynode']\n",
    "reg_alpha = tss['xgBoost']['specs'][0]['reg_alpha']\n",
    "reg_lambda = tss['xgBoost']['specs'][0]['reg_lambda']\n",
    "scale_pos_weight = tss['xgBoost']['specs'][0]['scale_pos_weight']\n",
    "base_score = tss['xgBoost']['specs'][0]['base_score']\n",
    "\n",
    "n_splits = tss['xgBoost']['specs'][0]['kFold_splits']\n",
    "\n",
    "print('                 ')\n",
    "print('Re-Training again for calculating f1 and train scores')\n",
    "\n",
    "xgbc = XGBClassifier(n_estimators=n_estimators, \n",
    "         max_depth=max_depth, learning_rate=learning_rate, \n",
    "         objective=objective, booster=booster,n_jobs=-1, \n",
    "         gamma=gamma, min_child_weight=min_child_weight, \n",
    "         max_delta_step=max_delta_step, subsample=subsample, \n",
    "         colsample_bytree=colsample_bytree, \n",
    "         colsample_bylevel=colsample_bylevel, colsample_bynode=colsample_bynode, \n",
    "         reg_alpha=reg_alpha, reg_lambda=reg_lambda, \n",
    "         scale_pos_weight=scale_pos_weight, base_score=base_score, random_state=0)\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all except LIT and FEMP\n",
    "ground_truth = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/District - Ground Truth - 2011&2001.csv\")\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "cols_2 = ['census_code', 'LIT_2001', 'FEMP_2001']\n",
    "femp_lit = femp_lit[cols_2]\n",
    "\n",
    "indicator = 'CHH'\n",
    "\n",
    "cols = ['census_code', indicator+'_2001', indicator+'_2011']\n",
    "gt = ground_truth[cols]\n",
    "\n",
    "df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data/CHH_CC.csv\")\n",
    "\n",
    "data = gt.merge(df,on='census_code', how='left')\n",
    "data = femp_lit.merge(data, on='census_code', how='left')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>LIT_2001</th>\n",
       "      <th>FEMP_2001</th>\n",
       "      <th>CHH_2001</th>\n",
       "      <th>CHH_2011</th>\n",
       "      <th>predictions_2001</th>\n",
       "      <th>predictions_2003</th>\n",
       "      <th>predictions_2005</th>\n",
       "      <th>predictions_2007</th>\n",
       "      <th>predictions_2009</th>\n",
       "      <th>predictions_2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  LIT_2001  FEMP_2001  CHH_2001  CHH_2011  predictions_2001  \\\n",
       "0            1         1          2         1         1               1.0   \n",
       "1            2         1          2         1         2               1.0   \n",
       "3            4         1          3         1         1               1.0   \n",
       "4            5         1          2         1         1               1.0   \n",
       "5            6         1          2         1         2               1.0   \n",
       "\n",
       "   predictions_2003  predictions_2005  predictions_2007  predictions_2009  \\\n",
       "0               3.0               1.0               1.0               1.0   \n",
       "1               1.0               1.0               1.0               1.0   \n",
       "3               2.0               2.0               2.0               2.0   \n",
       "4               3.0               3.0               3.0               3.0   \n",
       "5               3.0               1.0               3.0               3.0   \n",
       "\n",
       "   predictions_2011  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "3               2.0  \n",
       "4               3.0  \n",
       "5               3.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LIT and FEMP\n",
    "\n",
    "# ground_truth = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/District - Ground Truth - 2011&2001.csv\")\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "# cols_2 = ['census_code', 'LIT_2001', 'FEMP_2001']\n",
    "# femp_lit = femp_lit[cols_2]\n",
    "\n",
    "# For LIT\n",
    "# indicator = 'LIT'\n",
    "# cols = ['census_code', indicator+'_2001', indicator+'_2011', 'FEMP_2001']\n",
    "\n",
    "# For FEMP\n",
    "indicator = 'FEMP'\n",
    "cols = ['census_code', indicator+'_2001', indicator+'_2011', 'LIT_2001']\n",
    "\n",
    "gt = femp_lit[cols]\n",
    "\n",
    "# df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data/CHH_CC.csv\")\n",
    "df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data/FEMP_CC.csv\")\n",
    "\n",
    "data = gt.merge(df,on='census_code', how='left')\n",
    "# data = femp_lit.merge(data, on='census_code', how='left')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>FEMP_2001</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>LIT_2001</th>\n",
       "      <th>predictions_2001</th>\n",
       "      <th>predictions_2003</th>\n",
       "      <th>predictions_2005</th>\n",
       "      <th>predictions_2007</th>\n",
       "      <th>predictions_2009</th>\n",
       "      <th>predictions_2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  FEMP_2001  FEMP_2011  LIT_2001  predictions_2001  \\\n",
       "0            1          2          2         1               2.0   \n",
       "1            2          2          2         1               2.0   \n",
       "3            4          3          3         1               3.0   \n",
       "4            5          2          2         1               2.0   \n",
       "5            6          2          2         1               2.0   \n",
       "\n",
       "   predictions_2003  predictions_2005  predictions_2007  predictions_2009  \\\n",
       "0               2.0               2.0               2.0               3.0   \n",
       "1               2.0               2.0               2.0               3.0   \n",
       "3               3.0               3.0               3.0               3.0   \n",
       "4               2.0               2.0               2.0               2.0   \n",
       "5               2.0               2.0               2.0               2.0   \n",
       "\n",
       "   predictions_2011  \n",
       "0               2.0  \n",
       "1               2.0  \n",
       "3               3.0  \n",
       "4               2.0  \n",
       "5               2.0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [indicator+'_2001','LIT_2001','FEMP_2001','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "# For Lit\n",
    "# feature_cols = [indicator+'_2001','FEMP_2001','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "# For FEMP\n",
    "feature_cols = [indicator+'_2001','LIT_2001','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "target = indicator+'_2011'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[feature_cols].values\n",
    "y = data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_codes = data['census_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8892221190341597 0.9292642840692587 0.8879310344827587 0.9292364990689013\n",
      "1 0.8271220159151195 0.9260971987983836 0.8275862068965517 0.9259259259259259\n",
      "2 0.8954632715155028 0.9282973502772535 0.896551724137931 0.9281767955801105\n",
      "3 0.8606859172039996 0.93373757466658 0.8620689655172413 0.9333333333333333\n",
      "4 0.8645160908617594 0.9415772628977244 0.8620689655172413 0.9413919413919414\n",
      "------\n",
      "0.8674018829061081 0.93179473414184 0.8672413793103448 0.9316128990600425\n"
     ]
    }
   ],
   "source": [
    "val_f1score = []\n",
    "val_accscore = []\n",
    "train_f1score = []\n",
    "train_accscore = []\n",
    "# f1score = []\n",
    "# accscore = []\n",
    "final_df_fc = []\n",
    "counter=0\n",
    "for train_index, test_index in cv.split(X):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    \n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    best_xgb = xgbc.fit(X_train, y_train)\n",
    "    \n",
    "#     prediction_2011 = best_xgb.predict(X_2011)\n",
    "#     f1_weight = f1_score(y_2011, prediction_2011, average='weighted')\n",
    "#     acc = accuracy_score(y_2011, prediction_2011)\n",
    "\n",
    "#     f1score.append(f1_weight)\n",
    "#     accscore.append(acc)\n",
    "    \n",
    "    census_split = census_codes[test_index]\n",
    "    predictions = best_xgb.predict(X_test)\n",
    "    predictions_train = best_xgb.predict(X_train)\n",
    "    \n",
    "    final_predictions = np.stack((census_split, predictions))\n",
    "    final_predictions_df = pd.DataFrame(final_predictions)\n",
    "    final_predictions_df = final_predictions_df.transpose()\n",
    "    final_predictions_df.columns = ['census_code', 'CHH_prediction_2011']\n",
    "    final_df_fc.append(final_predictions_df)\n",
    "    \n",
    "\n",
    "    f1_weight = f1_score(y_test, predictions, average='weighted')\n",
    "    f1_weight_train = f1_score(y_train, predictions_train, average='weighted')\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    acc_train = accuracy_score(y_train, predictions_train)\n",
    "    print(counter, f1_weight, f1_weight_train, acc, acc_train)\n",
    "    counter=counter+1\n",
    "\n",
    "    val_f1score.append(f1_weight)\n",
    "    train_f1score.append(f1_weight_train)\n",
    "    val_accscore.append(acc)\n",
    "    train_accscore.append(acc_train)\n",
    "\n",
    "val_f1score = np.array(val_f1score).mean()\n",
    "train_f1score = np.array(train_f1score).mean()\n",
    "val_accscore = np.array(val_accscore).mean()\n",
    "train_accscore = np.array(train_accscore).mean()\n",
    "print('------')\n",
    "print(val_f1score, train_f1score, val_accscore, train_accscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.concat(final_df_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv('Results_Chahat/FEMP_FC_2011.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model has been trained now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_f1_score  [0.8790338989833988, 0.8730276008430247, 0.8687923097390229, 0.8643965745654454, 0.8562879355679154]\n",
      "train_f1_score  [0.9474524837233117, 0.949991423692485, 0.95726378143306, 0.9581513592364045, 0.9559358390455802]\n"
     ]
    }
   ],
   "source": [
    "tss = pickle.load( open(\"/Users/arpitjain/Downloads/SatPRo/mlpros/classifier_cv/Temporal_Transferability/FC_2001_TT_FEMP&LIT_2011_base_XGB.pkl\", 'rb'))\n",
    "# tss = pickle.load( open(\"/Users/arpitjain/Downloads/SatPRo/mlpros/classifier_cv/Temporal_Transferability/LIT_2001_TT_Current+base_XGB.pkl\", 'rb'))\n",
    "print('val_f1_score ',tss['xgBoost']['val_scores'])\n",
    "print('train_f1_score ',tss['xgBoost']['train_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 \n",
      "Re-Training again for calculating f1 and train scores\n"
     ]
    }
   ],
   "source": [
    "n_estimators = tss['xgBoost']['specs'][0]['n_estimators']\n",
    "max_depth = tss['xgBoost']['specs'][0]['max_depth']\n",
    "learning_rate = tss['xgBoost']['specs'][0]['learning_rate']\n",
    "objective = tss['xgBoost']['specs'][0]['objective']\n",
    "booster = tss['xgBoost']['specs'][0]['booster']\n",
    "gamma = tss['xgBoost']['specs'][0]['gamma']\n",
    "min_child_weight = tss['xgBoost']['specs'][0]['min_child_weight']\n",
    "max_delta_step = tss['xgBoost']['specs'][0]['max_delta_step']\n",
    "subsample = tss['xgBoost']['specs'][0]['subsample']\n",
    "colsample_bytree = tss['xgBoost']['specs'][0]['colsample_bytree']\n",
    "colsample_bylevel = tss['xgBoost']['specs'][0]['colsample_bylevel']\n",
    "colsample_bynode = tss['xgBoost']['specs'][0]['colsample_bynode']\n",
    "reg_alpha = tss['xgBoost']['specs'][0]['reg_alpha']\n",
    "reg_lambda = tss['xgBoost']['specs'][0]['reg_lambda']\n",
    "scale_pos_weight = tss['xgBoost']['specs'][0]['scale_pos_weight']\n",
    "base_score = tss['xgBoost']['specs'][0]['base_score']\n",
    "\n",
    "n_splits = tss['xgBoost']['specs'][0]['kFold_splits']\n",
    "\n",
    "print('                 ')\n",
    "print('Re-Training again for calculating f1 and train scores')\n",
    "\n",
    "xgbc = XGBClassifier(n_estimators=n_estimators, \n",
    "         max_depth=max_depth, learning_rate=learning_rate, \n",
    "         objective=objective, booster=booster,n_jobs=-1, \n",
    "         gamma=gamma, min_child_weight=min_child_weight, \n",
    "         max_delta_step=max_delta_step, subsample=subsample, \n",
    "         colsample_bytree=colsample_bytree, \n",
    "         colsample_bylevel=colsample_bylevel, colsample_bynode=colsample_bynode, \n",
    "         reg_alpha=reg_alpha, reg_lambda=reg_lambda, \n",
    "         scale_pos_weight=scale_pos_weight, base_score=base_score, random_state=0)\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.1,\n",
       " 'verbosity': 1,\n",
       " 'objective': 'multi:softmax',\n",
       " 'booster': 'gbtree',\n",
       " 'n_jobs': -1,\n",
       " 'gamma': 0,\n",
       " 'min_child_weight': 8,\n",
       " 'max_delta_step': 6,\n",
       " 'subsample': 0.7,\n",
       " 'colsample_bytree': 1,\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bynode': 0.9,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'base_score': 0.5,\n",
       " 'random_state': 0,\n",
       " 'importance_type': 'gain',\n",
       " 'n_randomized_search': 200,\n",
       " 'run_type': 'train-test',\n",
       " 'trail': 0,\n",
       " 'trail_type': 'sales',\n",
       " 'train_ratio': 0.9,\n",
       " 'val_train_loss': 'f1_weighted',\n",
       " 'top_n_models_drill': 5,\n",
       " 'top_n_models_pred': 5,\n",
       " 'n_drill_search': [100],\n",
       " 'test_ratio': 0.0,\n",
       " 'y_col': 'FC_2001',\n",
       " 'cols_to_drop': [],\n",
       " 'ensemble': False,\n",
       " 'n_cols_dropped': 0,\n",
       " 'current_date_col': 'census_code',\n",
       " 'no_steps_ahead': 0,\n",
       " 'apply_smote': True,\n",
       " 'time_cols': [],\n",
       " 'cross_validation': ['KFold'],\n",
       " 'kFold_splits': 5,\n",
       " 'pFold_splits': 20,\n",
       " 'feature_cols': ['FC_2011',\n",
       "  'LIT_2011',\n",
       "  'FEMP_2011',\n",
       "  'predictions_2003',\n",
       "  'predictions_2005',\n",
       "  'predictions_2007',\n",
       "  'predictions_2009'],\n",
       " 'input_order': Index(['LIT_2011', 'FEMP_2011', 'FC_2001', 'FC_2011', 'predictions_2001',\n",
       "        'predictions_2003', 'predictions_2005', 'predictions_2007',\n",
       "        'predictions_2009', 'predictions_2011'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tss['xgBoost']['specs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For All except LIT and FEMP\n",
    "\n",
    "ground_truth = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/District - Ground Truth - 2011&2001.csv\")\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "cols_2 = ['census_code', 'LIT_2011', 'FEMP_2011']\n",
    "femp_lit = femp_lit[cols_2]\n",
    "\n",
    "indicator = 'FC'\n",
    "\n",
    "cols = ['census_code', indicator+'_2001', indicator+'_2011']\n",
    "gt = ground_truth[cols]\n",
    "\n",
    "df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data_2011/FC_CC.csv\")\n",
    "\n",
    "data = gt.merge(df,on='census_code', how='left')\n",
    "data = femp_lit.merge(data, on='census_code', how='left')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>LIT_2011</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>FC_2001</th>\n",
       "      <th>FC_2011</th>\n",
       "      <th>predictions_2001</th>\n",
       "      <th>predictions_2003</th>\n",
       "      <th>predictions_2005</th>\n",
       "      <th>predictions_2007</th>\n",
       "      <th>predictions_2009</th>\n",
       "      <th>predictions_2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  LIT_2011  FEMP_2011  FC_2001  FC_2011  predictions_2001  \\\n",
       "0            1         1          2        1        1               1.0   \n",
       "1            2         1          2        2        1               1.0   \n",
       "3            4         2          3        2        1               3.0   \n",
       "4            5         1          2        1        1               1.0   \n",
       "5            6         1          2        1        1               1.0   \n",
       "\n",
       "   predictions_2003  predictions_2005  predictions_2007  predictions_2009  \\\n",
       "0               1.0               1.0               1.0               1.0   \n",
       "1               1.0               1.0               1.0               1.0   \n",
       "3               1.0               1.0               1.0               1.0   \n",
       "4               1.0               1.0               1.0               1.0   \n",
       "5               1.0               1.0               1.0               1.0   \n",
       "\n",
       "   predictions_2011  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "5               1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LIT and FEMP\n",
    "\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "\n",
    "# For LIT\n",
    "indicator = 'LIT'\n",
    "cols = ['census_code', indicator+'_2001', indicator+'_2011', 'FEMP_2011']\n",
    "\n",
    "# For FEMP\n",
    "# indicator = 'FEMP'\n",
    "# cols = ['census_code', indicator+'_2001', indicator+'_2011', 'LIT_2011']\n",
    "\n",
    "gt = femp_lit[cols]\n",
    "\n",
    "# df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data/CHH_CC.csv\")\n",
    "df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data_2011/LIT_CC.csv\")\n",
    "\n",
    "data = gt.merge(df,on='census_code', how='left')\n",
    "# data = femp_lit.merge(data, on='census_code', how='left')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>LIT_2001</th>\n",
       "      <th>LIT_2011</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>predictions_2001</th>\n",
       "      <th>predictions_2003</th>\n",
       "      <th>predictions_2005</th>\n",
       "      <th>predictions_2007</th>\n",
       "      <th>predictions_2009</th>\n",
       "      <th>predictions_2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  LIT_2001  LIT_2011  FEMP_2011  predictions_2001  \\\n",
       "0            1         1         1          2               1.0   \n",
       "1            2         1         1          2               1.0   \n",
       "3            4         1         2          3               3.0   \n",
       "4            5         1         1          2               1.0   \n",
       "5            6         1         1          2               1.0   \n",
       "\n",
       "   predictions_2003  predictions_2005  predictions_2007  predictions_2009  \\\n",
       "0               3.0               1.0               1.0               1.0   \n",
       "1               1.0               1.0               1.0               1.0   \n",
       "3               2.0               2.0               2.0               2.0   \n",
       "4               3.0               1.0               3.0               1.0   \n",
       "5               3.0               1.0               1.0               1.0   \n",
       "\n",
       "   predictions_2011  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "3               2.0  \n",
       "4               1.0  \n",
       "5               1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [indicator+'_2011','LIT_2011','FEMP_2011','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "# feature_cols = [indicator+'_2001','LIT_2001','FEMP_2001','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "# For Lit\n",
    "feature_cols = [indicator+'_2011','FEMP_2011','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "# For FEMP\n",
    "# feature_cols = [indicator+'_2011','LIT_2011','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "target = indicator+'_2001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIT_2011</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>predictions_2003</th>\n",
       "      <th>predictions_2005</th>\n",
       "      <th>predictions_2007</th>\n",
       "      <th>predictions_2009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIT_2011  FEMP_2011  predictions_2003  predictions_2005  predictions_2007  \\\n",
       "0         1          2               3.0               1.0               1.0   \n",
       "1         1          2               1.0               1.0               1.0   \n",
       "\n",
       "   predictions_2009  \n",
       "0               1.0  \n",
       "1               1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[feature_cols].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "Name: LIT_2001, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[target].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[feature_cols].values\n",
    "y = data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_codes = data['census_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7575757575757576 0.8640450063108482 0.7758620689655172 0.867595818815331\n",
      "1 0.8081819865120813 0.8520874986967155 0.8103448275862069 0.8588807785888077\n",
      "2 0.7733427163969037 0.869639969356282 0.7844827586206896 0.8736842105263158\n",
      "3 0.7610841916703985 0.8670985455723776 0.7672413793103449 0.8711864406779661\n",
      "4 0.6982276247967143 0.8676708507429746 0.7068965517241379 0.8722415795586528\n",
      "------\n",
      "0.759682455390371 0.8641083741358395 0.7689655172413793 0.8687177656334146\n"
     ]
    }
   ],
   "source": [
    "val_f1score = []\n",
    "val_accscore = []\n",
    "train_f1score = []\n",
    "train_accscore = []\n",
    "# f1score = []\n",
    "# accscore = []\n",
    "final_df_fc = []\n",
    "counter=0\n",
    "for train_index, test_index in cv.split(X):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    \n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    best_xgb = xgbc.fit(X_train, y_train)\n",
    "    \n",
    "#     prediction_2011 = best_xgb.predict(X_2011)\n",
    "#     f1_weight = f1_score(y_2011, prediction_2011, average='weighted')\n",
    "#     acc = accuracy_score(y_2011, prediction_2011)\n",
    "\n",
    "#     f1score.append(f1_weight)\n",
    "#     accscore.append(acc)\n",
    "    \n",
    "    census_split = census_codes[test_index]\n",
    "    predictions = best_xgb.predict(X_test)\n",
    "    predictions_train = best_xgb.predict(X_train)\n",
    "    \n",
    "    final_predictions = np.stack((census_split, predictions))\n",
    "    final_predictions_df = pd.DataFrame(final_predictions)\n",
    "    final_predictions_df = final_predictions_df.transpose()\n",
    "    final_predictions_df.columns = ['census_code', 'LIT_prediction_2001']\n",
    "    final_df_fc.append(final_predictions_df)\n",
    "    \n",
    "\n",
    "    f1_weight = f1_score(y_test, predictions, average='weighted')\n",
    "    f1_weight_train = f1_score(y_train, predictions_train, average='weighted')\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    acc_train = accuracy_score(y_train, predictions_train)\n",
    "    print(counter, f1_weight, f1_weight_train, acc, acc_train)\n",
    "    counter=counter+1\n",
    "\n",
    "    val_f1score.append(f1_weight)\n",
    "    train_f1score.append(f1_weight_train)\n",
    "    val_accscore.append(acc)\n",
    "    train_accscore.append(acc_train)\n",
    "\n",
    "val_f1score = np.array(val_f1score).mean()\n",
    "train_f1score = np.array(train_f1score).mean()\n",
    "val_accscore = np.array(val_accscore).mean()\n",
    "train_accscore = np.array(train_accscore).mean()\n",
    "print('------')\n",
    "print(val_f1score, train_f1score, val_accscore, train_accscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.concat(final_df_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv('LIT_BC_2001.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use model trained on\n",
    "    - current 2001, prediction_2003-2009, FEMP_2001, LIT_2001 to give output on 2011\n",
    "\n",
    "2. Give it input as\n",
    "    - current_2011, prediction_2011-2017 (obtained using model trained on 2011), FEMP_2011, LIT_2011 to give output on 2019\n",
    "    - current_2011, prediction_2013-2019 (obtained using model trained on 2011), FEMP_2011, LIT_2011 to give output on 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_f1_score  [0.8913233525244925, 0.8811188053001414, 0.8808806812808957, 0.8796172436073361, 0.872538909198773]\n",
      "train_f1_score  [0.9157949654427109, 0.9149759958846001, 0.9305906802828747, 0.9276685157918857, 0.9319774091533223]\n"
     ]
    }
   ],
   "source": [
    "# tss = pickle.load( open(\"/Users/arpitjain/Downloads/SatPRo/mlpros/classifier_cv/Temporal_Transferability/MSW_2011_TT_FEMP&LIT_base_XGB.pkl\", 'rb'))\n",
    "# tss = pickle.load( open(\"/Users/arpitjain/Downloads/SatPRo/mlpros/classifier_cv/Temporal_Transferability/MSW_2001_TT_FEMP&LIT_2011_base_XGB.pkl\", 'rb'))\n",
    "tss = pickle.load( open(\"/Users/arpitjain/Downloads/SatPRo/mlpros/classifier_cv/Temporal_Transferability/FORMAL_EMP_2001_TT_Current+base_XGB.pkl\", 'rb'))\n",
    "print('val_f1_score ',tss['xgBoost']['val_scores'])\n",
    "print('train_f1_score ',tss['xgBoost']['train_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 \n",
      "Re-Training again for calculating f1 and train scores\n"
     ]
    }
   ],
   "source": [
    "n_estimators = tss['xgBoost']['specs'][0]['n_estimators']\n",
    "max_depth = tss['xgBoost']['specs'][0]['max_depth']\n",
    "learning_rate = tss['xgBoost']['specs'][0]['learning_rate']\n",
    "objective = tss['xgBoost']['specs'][0]['objective']\n",
    "booster = tss['xgBoost']['specs'][0]['booster']\n",
    "gamma = tss['xgBoost']['specs'][0]['gamma']\n",
    "min_child_weight = tss['xgBoost']['specs'][0]['min_child_weight']\n",
    "max_delta_step = tss['xgBoost']['specs'][0]['max_delta_step']\n",
    "subsample = tss['xgBoost']['specs'][0]['subsample']\n",
    "colsample_bytree = tss['xgBoost']['specs'][0]['colsample_bytree']\n",
    "colsample_bylevel = tss['xgBoost']['specs'][0]['colsample_bylevel']\n",
    "colsample_bynode = tss['xgBoost']['specs'][0]['colsample_bynode']\n",
    "reg_alpha = tss['xgBoost']['specs'][0]['reg_alpha']\n",
    "reg_lambda = tss['xgBoost']['specs'][0]['reg_lambda']\n",
    "scale_pos_weight = tss['xgBoost']['specs'][0]['scale_pos_weight']\n",
    "base_score = tss['xgBoost']['specs'][0]['base_score']\n",
    "\n",
    "n_splits = tss['xgBoost']['specs'][0]['kFold_splits']\n",
    "\n",
    "print('                 ')\n",
    "print('Re-Training again for calculating f1 and train scores')\n",
    "\n",
    "xgbc = XGBClassifier(n_estimators=n_estimators, \n",
    "         max_depth=max_depth, learning_rate=learning_rate, \n",
    "         objective=objective, booster=booster,n_jobs=-1, \n",
    "         gamma=gamma, min_child_weight=min_child_weight, \n",
    "         max_delta_step=max_delta_step, subsample=subsample, \n",
    "         colsample_bytree=colsample_bytree, \n",
    "         colsample_bylevel=colsample_bylevel, colsample_bynode=colsample_bynode, \n",
    "         reg_alpha=reg_alpha, reg_lambda=reg_lambda, \n",
    "         scale_pos_weight=scale_pos_weight, base_score=base_score, random_state=0)\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For All except Lit and FEMP\n",
    "ground_truth = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/District - Ground Truth - 2011&2001.csv\")\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "cols_2 = ['census_code', 'LIT_2001', 'FEMP_2001']\n",
    "femp_lit = femp_lit[cols_2]\n",
    "\n",
    "indicator = 'MSW'\n",
    "\n",
    "cols = ['census_code', indicator+'_2001', indicator+'_2011']\n",
    "gt = ground_truth[cols]\n",
    "\n",
    "df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data_2011/MSW_CC.csv\")\n",
    "\n",
    "data = gt.merge(df,on='census_code', how='left')\n",
    "data = femp_lit.merge(data, on='census_code', how='left')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LIT and FEMP\n",
    "\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "\n",
    "# For LIT\n",
    "# indicator = 'LIT'\n",
    "# cols = ['census_code', indicator+'_2001', indicator+'_2011', 'FEMP_2011']\n",
    "\n",
    "# For FEMP\n",
    "indicator = 'FEMP'\n",
    "cols = ['census_code', indicator+'_2001', indicator+'_2011', 'LIT_2011']\n",
    "\n",
    "gt = femp_lit[cols]\n",
    "\n",
    "# df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data/CHH_CC.csv\")\n",
    "df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data_2011/FEMP_CC.csv\")\n",
    "\n",
    "data = gt.merge(df,on='census_code', how='left')\n",
    "# data = femp_lit.merge(data, on='census_code', how='left')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>FEMP_2001</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>LIT_2011</th>\n",
       "      <th>predictions_2001</th>\n",
       "      <th>predictions_2003</th>\n",
       "      <th>predictions_2005</th>\n",
       "      <th>predictions_2007</th>\n",
       "      <th>predictions_2009</th>\n",
       "      <th>predictions_2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  FEMP_2001  FEMP_2011  LIT_2011  predictions_2001  \\\n",
       "0            1          2          2         1               2.0   \n",
       "1            2          2          2         1               3.0   \n",
       "3            4          3          3         2               2.0   \n",
       "4            5          2          2         1               3.0   \n",
       "5            6          2          2         1               2.0   \n",
       "\n",
       "   predictions_2003  predictions_2005  predictions_2007  predictions_2009  \\\n",
       "0               3.0               2.0               2.0               2.0   \n",
       "1               2.0               2.0               2.0               2.0   \n",
       "3               3.0               3.0               3.0               3.0   \n",
       "4               3.0               3.0               3.0               2.0   \n",
       "5               3.0               2.0               2.0               2.0   \n",
       "\n",
       "   predictions_2011  \n",
       "0               2.0  \n",
       "1               2.0  \n",
       "3               3.0  \n",
       "4               2.0  \n",
       "5               2.0  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>FEMP_2001</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>LIT_2011</th>\n",
       "      <th>predictions_2001</th>\n",
       "      <th>predictions_2003</th>\n",
       "      <th>predictions_2005</th>\n",
       "      <th>predictions_2007</th>\n",
       "      <th>predictions_2009</th>\n",
       "      <th>predictions_2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  FEMP_2001  FEMP_2011  LIT_2011  predictions_2001  \\\n",
       "0            1          2          2         1               2.0   \n",
       "1            2          2          2         1               3.0   \n",
       "3            4          3          3         2               2.0   \n",
       "4            5          2          2         1               3.0   \n",
       "5            6          2          2         1               2.0   \n",
       "\n",
       "   predictions_2003  predictions_2005  predictions_2007  predictions_2009  \\\n",
       "0               3.0               2.0               2.0               2.0   \n",
       "1               2.0               2.0               2.0               2.0   \n",
       "3               3.0               3.0               3.0               3.0   \n",
       "4               3.0               3.0               3.0               2.0   \n",
       "5               3.0               2.0               2.0               2.0   \n",
       "\n",
       "   predictions_2011  \n",
       "0               2.0  \n",
       "1               2.0  \n",
       "3               3.0  \n",
       "4               2.0  \n",
       "5               2.0  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [indicator+'_2011','LIT_2001','FEMP_2001','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "# For Lit\n",
    "# feature_cols = [indicator+'_2011','FEMP_2011','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "# For FEMP\n",
    "feature_cols = [indicator+'_2011','LIT_2011','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "\n",
    "target = indicator+'_2001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[feature_cols].values\n",
    "y = data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9051435122446227 0.9248999569764819 0.9051724137931034 0.9246704331450094\n",
      "1 0.8707362188380081 0.9332676739059218 0.8706896551724138 0.9333333333333333\n",
      "2 0.8519091593804237 0.9317632724252536 0.853448275862069 0.9314285714285714\n",
      "3 0.8649904829356824 0.9366109001258256 0.8620689655172413 0.9365079365079365\n",
      "4 0.8791635528984734 0.9295688030233998 0.8793103448275862 0.9296296296296296\n",
      "------\n",
      "0.8743885852594421 0.9312221212913764 0.8741379310344828 0.931113980808896\n"
     ]
    }
   ],
   "source": [
    "val_f1score = []\n",
    "val_accscore = []\n",
    "train_f1score = []\n",
    "train_accscore = []\n",
    "# f1score = []\n",
    "# accscore = []\n",
    "counter=0\n",
    "for train_index, test_index in cv.split(X):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    \n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    best_xgb = xgbc.fit(X_train, y_train)\n",
    "    \n",
    "#     prediction_2011 = best_xgb.predict(X_2011)\n",
    "#     f1_weight = f1_score(y_2011, prediction_2011, average='weighted')\n",
    "#     acc = accuracy_score(y_2011, prediction_2011)\n",
    "\n",
    "#     f1score.append(f1_weight)\n",
    "#     accscore.append(acc)\n",
    "\n",
    "    predictions = best_xgb.predict(X_test)\n",
    "    predictions_train = best_xgb.predict(X_train)\n",
    "\n",
    "    f1_weight = f1_score(y_test, predictions, average='weighted')\n",
    "    f1_weight_train = f1_score(y_train, predictions_train, average='weighted')\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    acc_train = accuracy_score(y_train, predictions_train)\n",
    "    print(counter, f1_weight, f1_weight_train, acc, acc_train)\n",
    "    counter=counter+1\n",
    "\n",
    "    val_f1score.append(f1_weight)\n",
    "    train_f1score.append(f1_weight_train)\n",
    "    val_accscore.append(acc)\n",
    "    train_accscore.append(acc_train)\n",
    "\n",
    "val_f1score = np.array(val_f1score).mean()\n",
    "train_f1score = np.array(train_f1score).mean()\n",
    "val_accscore = np.array(val_accscore).mean()\n",
    "train_accscore = np.array(train_accscore).mean()\n",
    "print('------')\n",
    "print(val_f1score, train_f1score, val_accscore, train_accscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data_2011-19/FEMP_CC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ALL Except LIT and FEMP\n",
    "ground_truth = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/District - Ground Truth - 2011&2001.csv\")\n",
    "gt_cols = ['census_code','MSW_2011']\n",
    "\n",
    "ground_truth = ground_truth[gt_cols]\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "cols_2 = ['census_code', 'LIT_2011', 'FEMP_2011']\n",
    "femp_lit = femp_lit[cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 2)\n",
      "(593, 3)\n",
      "(593, 4)\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.shape)\n",
    "print(femp_lit.shape)\n",
    "gt_femlit = ground_truth.merge(femp_lit, on='census_code', how='left')\n",
    "gt_femlit.dropna(inplace=True)\n",
    "print(gt_femlit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For LIT and FEMP\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "cols_2 = ['census_code', 'LIT_2011', 'FEMP_2011']\n",
    "gt_femlit = femp_lit[cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 8)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut = gt_femlit.merge(file, on='census_code', how='left')\n",
    "X_test_fut.dropna(inplace=True)\n",
    "X_test_fut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>LIT_2011</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>predictions_2011</th>\n",
       "      <th>predictions_2013</th>\n",
       "      <th>predictions_2015</th>\n",
       "      <th>predictions_2017</th>\n",
       "      <th>predictions_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  LIT_2011  FEMP_2011  predictions_2011  predictions_2013  \\\n",
       "0            1         1          2               2.0               2.0   \n",
       "1            2         1          2               2.0               2.0   \n",
       "2            3         2          3               3.0               2.0   \n",
       "3            4         2          3               3.0               2.0   \n",
       "4            5         1          2               2.0               3.0   \n",
       "\n",
       "   predictions_2015  predictions_2017  predictions_2019  \n",
       "0               2.0               2.0               3.0  \n",
       "1               2.0               2.0               2.0  \n",
       "2               3.0               3.0               3.0  \n",
       "3               2.0               3.0               2.0  \n",
       "4               3.0               3.0               3.0  "
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>LIT_2011</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>predictions_2011</th>\n",
       "      <th>predictions_2013</th>\n",
       "      <th>predictions_2015</th>\n",
       "      <th>predictions_2017</th>\n",
       "      <th>predictions_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  LIT_2011  FEMP_2011  predictions_2011  predictions_2013  \\\n",
       "0            1         1          2               2.0               2.0   \n",
       "1            2         1          2               2.0               2.0   \n",
       "2            3         2          3               3.0               2.0   \n",
       "3            4         2          3               3.0               2.0   \n",
       "4            5         1          2               2.0               3.0   \n",
       "\n",
       "   predictions_2015  predictions_2017  predictions_2019  \n",
       "0               2.0               2.0               3.0  \n",
       "1               2.0               2.0               2.0  \n",
       "2               3.0               3.0               3.0  \n",
       "3               2.0               3.0               2.0  \n",
       "4               3.0               3.0               3.0  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['census_code', 'LIT_2011', 'FEMP_2011', 'predictions_2011',\n",
       "       'predictions_2013', 'predictions_2015', 'predictions_2017',\n",
       "       'predictions_2019'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_codes = X_test_fut['census_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE that order should be same\n",
    "\n",
    "# cols_fut = ['MSW_2011', 'LIT_2011', 'FEMP_2011','predictions_2011', 'predictions_2013', 'predictions_2015','predictions_2017']\n",
    "\n",
    "# For Lit\n",
    "cols_fut = ['LIT_2011', 'FEMP_2011','predictions_2011', 'predictions_2013', 'predictions_2015','predictions_2017']\n",
    "\n",
    "# For FEMP\n",
    "cols_fut = ['FEMP_2011','LIT_2011','predictions_2011', 'predictions_2013', 'predictions_2015','predictions_2017']\n",
    "\n",
    "X_test_fut = X_test_fut[cols_fut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(540, 6)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut = X_test_fut.values\n",
    "\n",
    "X_test_fut.shape\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_future = best_xgb.predict(X_test_fut)\n",
    "\n",
    "predictions_future.shape\n",
    "\n",
    "census_codes.shape\n",
    "\n",
    "final_predictions = np.stack((census_codes, predictions_future))\n",
    "\n",
    "final_predictions.shape\n",
    "\n",
    "final_predictions_df = pd.DataFrame(final_predictions)\n",
    "\n",
    "final_predictions_df = final_predictions_df.transpose()\n",
    "\n",
    "final_predictions_df.columns = ['census_code', 'prediction_2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>prediction_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  prediction_2019\n",
       "0            1                2\n",
       "1            2                2\n",
       "2            3                3\n",
       "3            4                3\n",
       "4            5                2"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    220\n",
       "3    194\n",
       "1    175\n",
       "Name: prediction_2019, dtype: int64"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions_df['prediction_2019'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>prediction_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>635</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>636</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>637</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>638</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>639</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     census_code  prediction_2019\n",
       "0              1                2\n",
       "1              2                2\n",
       "2              3                3\n",
       "3              4                3\n",
       "4              5                2\n",
       "..           ...              ...\n",
       "584          635                3\n",
       "585          636                3\n",
       "586          637                3\n",
       "587          638                3\n",
       "588          639                3\n",
       "\n",
       "[589 rows x 2 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df.to_csv('Future_FEMP_2019_UsingM2011.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
