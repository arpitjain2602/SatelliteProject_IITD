{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Methods (as in point 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use model trained on\n",
    "    - current 2001, prediction_2003-2009, FEMP_2001, LIT_2001 to give output on 2011\n",
    "\n",
    "2. Give it input as\n",
    "    - current_2011, prediction_2011-2017 (obtained using model trained on 2011), FEMP_2011, LIT_2011 to give output on 2019\n",
    "    - current_2011, prediction_2013-2019 (obtained using model trained on 2011), FEMP_2011, LIT_2011 to give output on 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_f1_score  [0.8270129911945027, 0.8159965598837557, 0.8113614817624573, 0.802237520193312, 0.8005558525591013]\n",
      "train_f1_score  [0.9323896729776345, 0.9321812129150029, 0.9317655562340313, 0.9327571316386016, 0.9326533218886478]\n"
     ]
    }
   ],
   "source": [
    "tss = pickle.load( open(\"/Users/arpitjain/Downloads/SatPRo/mlpros/classifier_cv/Temporal_Transferability/MSW_2011_TT_FEMP&LIT_base_XGB.pkl\", 'rb'))\n",
    "print('val_f1_score ',tss['xgBoost']['val_scores'])\n",
    "print('train_f1_score ',tss['xgBoost']['train_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 \n",
      "Re-Training again for calculating f1 and train scores\n"
     ]
    }
   ],
   "source": [
    "n_estimators = tss['xgBoost']['specs'][0]['n_estimators']\n",
    "max_depth = tss['xgBoost']['specs'][0]['max_depth']\n",
    "learning_rate = tss['xgBoost']['specs'][0]['learning_rate']\n",
    "objective = tss['xgBoost']['specs'][0]['objective']\n",
    "booster = tss['xgBoost']['specs'][0]['booster']\n",
    "gamma = tss['xgBoost']['specs'][0]['gamma']\n",
    "min_child_weight = tss['xgBoost']['specs'][0]['min_child_weight']\n",
    "max_delta_step = tss['xgBoost']['specs'][0]['max_delta_step']\n",
    "subsample = tss['xgBoost']['specs'][0]['subsample']\n",
    "colsample_bytree = tss['xgBoost']['specs'][0]['colsample_bytree']\n",
    "colsample_bylevel = tss['xgBoost']['specs'][0]['colsample_bylevel']\n",
    "colsample_bynode = tss['xgBoost']['specs'][0]['colsample_bynode']\n",
    "reg_alpha = tss['xgBoost']['specs'][0]['reg_alpha']\n",
    "reg_lambda = tss['xgBoost']['specs'][0]['reg_lambda']\n",
    "scale_pos_weight = tss['xgBoost']['specs'][0]['scale_pos_weight']\n",
    "base_score = tss['xgBoost']['specs'][0]['base_score']\n",
    "\n",
    "n_splits = tss['xgBoost']['specs'][0]['kFold_splits']\n",
    "\n",
    "print('                 ')\n",
    "print('Re-Training again for calculating f1 and train scores')\n",
    "\n",
    "xgbc = XGBClassifier(n_estimators=n_estimators, \n",
    "         max_depth=max_depth, learning_rate=learning_rate, \n",
    "         objective=objective, booster=booster,n_jobs=-1, \n",
    "         gamma=gamma, min_child_weight=min_child_weight, \n",
    "         max_delta_step=max_delta_step, subsample=subsample, \n",
    "         colsample_bytree=colsample_bytree, \n",
    "         colsample_bylevel=colsample_bylevel, colsample_bynode=colsample_bynode, \n",
    "         reg_alpha=reg_alpha, reg_lambda=reg_lambda, \n",
    "         scale_pos_weight=scale_pos_weight, base_score=base_score, random_state=0)\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/District - Ground Truth - 2011&2001.csv\")\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "cols_2 = ['census_code', 'LIT_2001', 'FEMP_2001']\n",
    "femp_lit = femp_lit[cols_2]\n",
    "\n",
    "indicator = 'MSW'\n",
    "\n",
    "cols = ['census_code', indicator+'_2001', indicator+'_2011']\n",
    "gt = ground_truth[cols]\n",
    "\n",
    "df = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data/MSW_CC.csv\")\n",
    "\n",
    "data = gt.merge(df,on='census_code', how='left')\n",
    "data = femp_lit.merge(data, on='census_code', how='left')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>LIT_2001</th>\n",
       "      <th>FEMP_2001</th>\n",
       "      <th>MSW_2001</th>\n",
       "      <th>MSW_2011</th>\n",
       "      <th>predictions_2001</th>\n",
       "      <th>predictions_2003</th>\n",
       "      <th>predictions_2005</th>\n",
       "      <th>predictions_2007</th>\n",
       "      <th>predictions_2009</th>\n",
       "      <th>predictions_2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  LIT_2001  FEMP_2001  MSW_2001  MSW_2011  predictions_2001  \\\n",
       "0            1         1          2         1         1               1.0   \n",
       "1            2         1          2         3         3               3.0   \n",
       "3            4         1          3         1         3               1.0   \n",
       "4            5         1          2         1         1               1.0   \n",
       "5            6         1          2         1         1               1.0   \n",
       "\n",
       "   predictions_2003  predictions_2005  predictions_2007  predictions_2009  \\\n",
       "0               1.0               3.0               3.0               3.0   \n",
       "1               3.0               3.0               3.0               3.0   \n",
       "3               1.0               1.0               1.0               1.0   \n",
       "4               3.0               3.0               3.0               3.0   \n",
       "5               3.0               3.0               3.0               3.0   \n",
       "\n",
       "   predictions_2011  \n",
       "0               3.0  \n",
       "1               3.0  \n",
       "3               1.0  \n",
       "4               3.0  \n",
       "5               3.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [indicator+'_2001','LIT_2001','FEMP_2001','predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009']\n",
    "target = indicator+'_2011'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[feature_cols].values\n",
    "y = data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8363721664214275 0.9327865673880659 0.8275862068965517 0.9330218068535826\n",
      "1 0.8191615363914536 0.9326850460935188 0.8189655172413793 0.9327073552425665\n",
      "2 0.7969480661454986 0.9364927805058052 0.8017241379310345 0.9365853658536586\n",
      "3 0.8468013730691214 0.9257470558035039 0.8448275862068966 0.9261006289308176\n",
      "4 0.8023506724095454 0.9361304871555528 0.8017241379310345 0.9363636363636364\n",
      "------\n",
      "0.8203267628874092 0.9327683873892892 0.8189655172413793 0.9329557586488523\n"
     ]
    }
   ],
   "source": [
    "val_f1score = []\n",
    "val_accscore = []\n",
    "train_f1score = []\n",
    "train_accscore = []\n",
    "# f1score = []\n",
    "# accscore = []\n",
    "counter=0\n",
    "for train_index, test_index in cv.split(X):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    \n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    \n",
    "    best_xgb = xgbc.fit(X_train, y_train)\n",
    "    \n",
    "#     prediction_2011 = best_xgb.predict(X_2011)\n",
    "#     f1_weight = f1_score(y_2011, prediction_2011, average='weighted')\n",
    "#     acc = accuracy_score(y_2011, prediction_2011)\n",
    "\n",
    "#     f1score.append(f1_weight)\n",
    "#     accscore.append(acc)\n",
    "\n",
    "    predictions = best_xgb.predict(X_test)\n",
    "    predictions_train = best_xgb.predict(X_train)\n",
    "\n",
    "    f1_weight = f1_score(y_test, predictions, average='weighted')\n",
    "    f1_weight_train = f1_score(y_train, predictions_train, average='weighted')\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "    acc_train = accuracy_score(y_train, predictions_train)\n",
    "    print(counter, f1_weight, f1_weight_train, acc, acc_train)\n",
    "    counter=counter+1\n",
    "\n",
    "    val_f1score.append(f1_weight)\n",
    "    train_f1score.append(f1_weight_train)\n",
    "    val_accscore.append(acc)\n",
    "    train_accscore.append(acc_train)\n",
    "\n",
    "val_f1score = np.array(val_f1score).mean()\n",
    "train_f1score = np.array(train_f1score).mean()\n",
    "val_accscore = np.array(val_accscore).mean()\n",
    "train_accscore = np.array(train_accscore).mean()\n",
    "print('------')\n",
    "print(val_f1score, train_f1score, val_accscore, train_accscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model has been trained now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data_2011-19/MSW_CC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['census_code', 'predictions_2011', 'predictions_2013',\n",
       "       'predictions_2015', 'predictions_2017', 'predictions_2019'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/District - Ground Truth - 2011&2001.csv\")\n",
    "gt_cols = ['census_code','MSW_2011']\n",
    "\n",
    "ground_truth = ground_truth[gt_cols]\n",
    "femp_lit = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/FEMP&LIT.csv\")\n",
    "cols_2 = ['census_code', 'LIT_2011', 'FEMP_2011']\n",
    "femp_lit = femp_lit[cols_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(593, 2)\n",
      "(593, 3)\n",
      "(593, 4)\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth.shape)\n",
    "print(femp_lit.shape)\n",
    "gt_femlit = ground_truth.merge(femp_lit, on='census_code', how='left')\n",
    "gt_femlit.dropna(inplace=True)\n",
    "print(gt_femlit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut = gt_femlit.merge(file, on='census_code', how='left')\n",
    "X_test_fut.dropna(inplace=True)\n",
    "X_test_fut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>MSW_2011</th>\n",
       "      <th>LIT_2011</th>\n",
       "      <th>FEMP_2011</th>\n",
       "      <th>predictions_2011</th>\n",
       "      <th>predictions_2013</th>\n",
       "      <th>predictions_2015</th>\n",
       "      <th>predictions_2017</th>\n",
       "      <th>predictions_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  MSW_2011  LIT_2011  FEMP_2011  predictions_2011  \\\n",
       "0            1         1         1          2               1.0   \n",
       "1            2         3         1          2               3.0   \n",
       "2            3         1         2          3               1.0   \n",
       "3            4         3         2          3               3.0   \n",
       "4            5         1         1          2               1.0   \n",
       "\n",
       "   predictions_2013  predictions_2015  predictions_2017  predictions_2019  \n",
       "0               3.0               3.0               3.0               3.0  \n",
       "1               3.0               3.0               1.0               3.0  \n",
       "2               3.0               3.0               3.0               3.0  \n",
       "3               3.0               3.0               3.0               3.0  \n",
       "4               3.0               1.0               1.0               1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['census_code', 'MSW_2011', 'LIT_2011', 'FEMP_2011', 'predictions_2011',\n",
       "       'predictions_2013', 'predictions_2015', 'predictions_2017',\n",
       "       'predictions_2019'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_codes = X_test_fut['census_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE that order should be same\n",
    "\n",
    "cols_fut = ['MSW_2011', 'LIT_2011', 'FEMP_2011','predictions_2011', 'predictions_2013', 'predictions_2015','predictions_2017']\n",
    "X_test_fut = X_test_fut[cols_fut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fut = X_test_fut.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_fut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_future = best_xgb.predict(X_test_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_future.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = np.stack((census_codes, predictions_future))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 589)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df = pd.DataFrame(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df = final_predictions_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df.columns = ['census_code', 'prediction_2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>prediction_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  prediction_2019\n",
       "0            1                1\n",
       "1            2                3\n",
       "2            3                1\n",
       "3            4                3\n",
       "4            5                2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    263\n",
       "2    247\n",
       "1     79\n",
       "Name: prediction_2019, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions_df['prediction_2019'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions_df.to_csv('Future_MSW_2019_M1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
