{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "Cross-sectional district level models are run for which features generated by Arpit are used. For every indicator we have around 10 feature files (bin 5-15\n",
    "\n",
    "Will follow a 5fold cross-validation approach and take the mean of weighted f1-score\n",
    "\n",
    "Finally all scores will be reported for the best parameters\n",
    "\n",
    "Not running MLP for this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np                               \n",
    "import pandas as pd                              \n",
    "import csv\n",
    "import time\n",
    "import keras\n",
    "import pprint\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# mainly for stats models, and tensorflow,pandas version\n",
    "# related warnings, which should not be ignored ideally\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL) \n",
    "random.seed(5)\n",
    "np.random.seed(5)\n",
    "\n",
    "import src\n",
    "import specs\n",
    "\n",
    "# all the specs\n",
    "from specs.mlSpecs import *\n",
    "from specs.mlDrillSpecs import *\n",
    "from specs.ensembleSpecs import *\n",
    "# from specs.statsSpecs import *\n",
    "\n",
    "# all the classes and functions for dictionaries\n",
    "from src.scores import *\n",
    "\n",
    "from src.models.machineLearning.randomForest import randomForest\n",
    "from src.models.machineLearning.xgBoost import xgBoost\n",
    "from src.models.machineLearning.svc import svc\n",
    "from src.models.machineLearning.adaBoost import adaBoost\n",
    "from src.models.machineLearning.bagging import bagging\n",
    "from src.models.machineLearning.gradientBoosting import gradientBoosting\n",
    "from src.models.machineLearning.knn import knn\n",
    "from src.models.machineLearning.mlp import mlp\n",
    "from src.models.machineLearning.ensembleMLP import ensembleMLP\n",
    "\n",
    "from src.randomizedSearchSpecial import *\n",
    "\n",
    "#all other functions\n",
    "from src.dataPreprocessingUtils import *\n",
    "from src.selectorFunctions import *\n",
    "from src.mlPrediction import *\n",
    "from src.combining import *\n",
    "from src.randomizedSearch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 3 need to be defined outside in some file which is loaded\n",
    "scores_dict = {\n",
    "        \"f1_weighted\" : {\"function\" : f1_weighted, \"type\" : \"score\",},\n",
    "        \"f1_macro\" : {\"function\" : f1_macro, \"type\" : \"score\",},\n",
    "        \"f1_micro\" : {\"function\" : f1_micro, \"type\" : \"score\",},\n",
    "        \"accuracy_normal\" : {\"function\" : accuracy_normal, \"type\" : \"score\",},\n",
    "        \"accuracy_weighted\" : {\"function\" : accuracy_weighted, \"type\" : \"score\",},\n",
    "        \"accuracy_classwise\" : {\"function\" : accuracy_classwise, \"type\" : \"score\",},\n",
    "        \"precision_weighted\" : {\"function\" : precision_weighted, \"type\" : \"score\",},\n",
    "        \"precision_macro\" : {\"function\" : precision_macro, \"type\" : \"score\",},\n",
    "        \"precision_micro\" : {\"function\" : precision_micro, \"type\" : \"score\",},\n",
    "        \"recall_weighted\" : {\"function\" : recall_weighted, \"type\" : \"score\",},\n",
    "        \"recall_macro\" : {\"function\" : recall_macro, \"type\" : \"score\",},\n",
    "        \"recall_micro\" : {\"function\" : recall_micro, \"type\" : \"score\",},\n",
    "#         \"roc_auc_weighted\" : {\"function\" : roc_auc_weighted, \"type\" : \"score\",},\n",
    "#         \"roc_auc_macro\" : {\"function\" : roc_auc_macro, \"type\" : \"score\",},\n",
    "#         \"roc_auc_micro\" : {\"function\" : roc_auc_micro, \"type\" : \"score\",},\n",
    "        \"categorical_crossentropy\" : {\"type\" : \"error\",},\n",
    "        \"accuracy\" : {\"type\" : \"score\",},\n",
    "        \"acc\" : {\"type\" : \"score\",}\n",
    "    }\n",
    "models_dict = {\n",
    "#                 \"randomForest\" : {\"class\": randomForest , \"type\": \"machine_learning\"},\n",
    "                \"xgBoost\" : {\"class\": xgBoost , \"type\": \"machine_learning\"},\n",
    "#                 \"svc\" : {\"class\": svc , \"type\": \"machine_learning\"},\n",
    "#                 \"bagging\" : {\"class\": bagging , \"type\": \"machine_learning\"},\n",
    "#                 \"adaBoost\" : {\"class\": adaBoost , \"type\": \"machine_learning\"},\n",
    "#                 \"gradientBoosting\" : {\"class\": gradientBoosting , \"type\": \"machine_learning\"},\n",
    "#                 \"knn\" : {\"class\": knn , \"type\": \"machine_learning\"},\n",
    "#                 \"mlp\" : {\"class\": mlp , \"type\": \"machine_learning\"},\n",
    "}\n",
    "special_specs_functions = {\n",
    "    'randomForest' : multipleSpecialRFSpecs,\n",
    "    'mlp' : None,\n",
    "    'xgBoost' : None,\n",
    "    'svc' : multipleSpecialRFSpecs,\n",
    "    'adaBoost' : multipleSpecialRFSpecs,\n",
    "    'gradientBoosting' : multipleSpecialRFSpecs,\n",
    "    'bagging' : multipleSpecialRFSpecs,\n",
    "    'knn' : None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models that will be runnning...\n",
      "-------------------------------\n",
      "{'xgBoost': {'class': <class 'src.models.machineLearning.xgBoost.xgBoost'>,\n",
      "             'type': 'machine_learning'}}\n"
     ]
    }
   ],
   "source": [
    "print('Models that will be runnning...')\n",
    "print('-------------------------------')\n",
    "pprint.pprint(models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Updating the Common Specs\n"
     ]
    }
   ],
   "source": [
    "# Should be a separate function or file # For avoiding bugs and unexpected behaviours # which are hard to find later, no value \n",
    "# should be replaced, new values should be # added\n",
    "\n",
    "for key in specifications_master_dict.keys():\n",
    "    specifications_master_dict[key].update({\n",
    "          'n_randomized_search': { \n",
    "                        'value_type': 'constant',\n",
    "                        'values': [200]},\n",
    "          'test_ratio': { \n",
    "                        'value_type': 'constant',\n",
    "                        'values': [0.0]},\n",
    "          'y_col': { \n",
    "                      'value_type': 'constant',\n",
    "                      'values': []},          \n",
    "          'cols_to_drop': { \n",
    "                      'value_type': 'constant',\n",
    "                      'values': [[]]},\n",
    "           'ensemble': { \n",
    "                  'value_type': 'constant',\n",
    "                  'values': [False]},\n",
    "           'trail':  { \n",
    "                  'value_type': 'categories',\n",
    "                  'values': [0]},\n",
    "          'n_cols_dropped': { \n",
    "                      'value_type': 'constant',\n",
    "                      'values': [0]},\n",
    "          'current_date_col': { \n",
    "                      'value_type': 'constant',\n",
    "                      'values': []},\n",
    "          'no_steps_ahead': { \n",
    "                      'value_type': 'constant',\n",
    "                      'values': [0]},\n",
    "          'top_n_models_drill': { \n",
    "                             'value_type': 'constant',\n",
    "                             'values': [5]},\n",
    "          'top_n_models_pred': { \n",
    "                             'value_type': 'constant',\n",
    "                             'values': [5]},\n",
    "          'apply_smote': { \n",
    "                             'value_type': 'constant',\n",
    "                             'values': [True]},      # can be True or False\n",
    "          'time_cols': {    \n",
    "                             'value_type': 'constant',\n",
    "                             'values': [[]]},\n",
    "          'n_drill_search': { \n",
    "                     'value_type': 'constant',\n",
    "                     'values': [[100]]},\n",
    "          'cross_validation': { \n",
    "                     'value_type': 'constant',\n",
    "                     'values': [['KFold']]},     # can take values - KFold, LeaveOneOut, train_val_holdout\n",
    "                                                 # LeavePOut - in case of KFold & LeavePOut, we should have \n",
    "                                                 # additional parameter of k and p\n",
    "         'kFold_splits': { \n",
    "                             'value_type': 'categories',\n",
    "                             'values': [5]}, \n",
    "         'pFold_splits': { \n",
    "                             'value_type': 'categories',\n",
    "                             'values': [3,4,5,10,15,20]}, \n",
    "         'feature_cols': { \n",
    "                             'value_type': 'constant',\n",
    "                             'values': []},},\n",
    "    )\n",
    "# pprint.pprint(specifications_master_dict)\n",
    "print('Done Updating the Common Specs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(specifications_master_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_smote(data, feature_cols, target):\n",
    "#     '''\n",
    "#     Input:\n",
    "#     data - the original dataframe\n",
    "#     feature_cols - the feature columns (list of columns)\n",
    "#     target - the target column (string value)\n",
    "#     '''\n",
    "#     sm = SMOTE(random_state=42)\n",
    "#     features, targets = sm.fit_resample(data[feature_cols],data[target])\n",
    "#     feature_df = pd.DataFrame(features, columns=feature_cols)\n",
    "#     target_df = pd.DataFrame(targets, columns=[target])\n",
    "#     output = pd.concat([feature_df, target_df], axis=1)\n",
    "#     # Shuffling dataset\n",
    "#     output = output.sample(frac=1).reset_index(drop=True)\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(\"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/GroundTruth_ChangeClassifier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>census_code</th>\n",
       "      <th>MSW_change</th>\n",
       "      <th>MSW_2001</th>\n",
       "      <th>BF_change</th>\n",
       "      <th>BF_2001</th>\n",
       "      <th>CHH_change</th>\n",
       "      <th>CHH_2001</th>\n",
       "      <th>EMP_change</th>\n",
       "      <th>EMP_2001</th>\n",
       "      <th>MSL_change</th>\n",
       "      <th>MSL_2001</th>\n",
       "      <th>FC_change</th>\n",
       "      <th>FC_2001</th>\n",
       "      <th>ASSET_change</th>\n",
       "      <th>ASSET_2001</th>\n",
       "      <th>Formal_EMP_2001</th>\n",
       "      <th>LIT_2001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   census_code  MSW_change  MSW_2001  BF_change  BF_2001  CHH_change  \\\n",
       "0            1           0         1          0        2           0   \n",
       "1            2           0         3          0        2           1   \n",
       "2            3           0         1          0        2           1   \n",
       "3            4           1         1          1        2           0   \n",
       "4            5           0         1          0        1           0   \n",
       "\n",
       "   CHH_2001  EMP_change  EMP_2001  MSL_change  MSL_2001  FC_change  FC_2001  \\\n",
       "0         1           0         1           1         2          0        1   \n",
       "1         1           0         1           0         3          0        2   \n",
       "2         1           0         3           0         3          0        3   \n",
       "3         1           0         3           0         3          0        2   \n",
       "4         1           0         2           1         2          0        1   \n",
       "\n",
       "   ASSET_change  ASSET_2001  Formal_EMP_2001  LIT_2001  \n",
       "0             0           1                2         1  \n",
       "1             1           1                2         1  \n",
       "2             1           1                3         1  \n",
       "3             0           1                3         1  \n",
       "4             0           1                2         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Running for :  CHH_change\n",
      "CHH_change ['census_code', 'MSW_change', 'MSW_2001', 'BF_change', 'BF_2001', 'CHH_2001', 'EMP_change', 'EMP_2001', 'MSL_change', 'MSL_2001', 'FC_change', 'FC_2001', 'ASSET_change', 'ASSET_2001'] ['Formal_EMP_2001', 'LIT_2001', 'predictions_2001', 'predictions_2003', 'predictions_2005', 'predictions_2007', 'predictions_2009', 'predictions_2011']\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "Running model  xgBoost\n",
      "####### n_randomized_search [200]\n",
      "    run 0   CV Type ['KFold'] 5\n",
      "    run 1   CV Type ['KFold'] 5\n",
      "    run 2   CV Type ['KFold'] 5\n",
      "    run 3   CV Type ['KFold'] 5\n",
      "    run 4   CV Type ['KFold'] 5\n",
      "    run 5   CV Type ['KFold'] 5\n",
      "    run 6   CV Type ['KFold'] 5\n",
      "    run 7   CV Type ['KFold'] 5\n",
      "    run 8   CV Type ['KFold'] 5\n",
      "    run 9   CV Type ['KFold'] 5\n",
      "    run 10   CV Type ['KFold'] 5\n",
      "    run 11   CV Type ['KFold'] 5\n",
      "    run 12   CV Type ['KFold'] 5\n",
      "    run 13   CV Type ['KFold'] 5\n",
      "    run 14   CV Type ['KFold'] 5\n",
      "    run 15   CV Type ['KFold'] 5\n",
      "    run 16   CV Type ['KFold'] 5\n",
      "    run 17   CV Type ['KFold'] 5\n",
      "    run 18   CV Type ['KFold'] 5\n",
      "    run 19   CV Type ['KFold'] 5\n",
      "    run 20   CV Type ['KFold'] 5\n",
      "    run 21   CV Type ['KFold'] 5\n",
      "    run 22   CV Type ['KFold'] 5\n",
      "    run 23   CV Type ['KFold'] 5\n",
      "    run 24   CV Type ['KFold'] 5\n",
      "    run 25   CV Type ['KFold'] 5\n",
      "    run 26   CV Type ['KFold'] 5\n",
      "    run 27   CV Type ['KFold'] 5\n",
      "    run 28   CV Type ['KFold'] 5\n",
      "    run 29   CV Type ['KFold'] 5\n",
      "    run 30   CV Type ['KFold'] 5\n",
      "    run 31   CV Type ['KFold'] 5\n",
      "    run 32   CV Type ['KFold'] 5\n",
      "    run 33   CV Type ['KFold'] 5\n",
      "    run 34   CV Type ['KFold'] 5\n",
      "    run 35   CV Type ['KFold'] 5\n",
      "    run 36   CV Type ['KFold'] 5\n",
      "    run 37   CV Type ['KFold'] 5\n",
      "    run 38   CV Type ['KFold'] 5\n",
      "    run 39   CV Type ['KFold'] 5\n",
      "    run 40   CV Type ['KFold'] 5\n",
      "    run 41   CV Type ['KFold'] 5\n",
      "    run 42   CV Type ['KFold'] 5\n",
      "    run 43   CV Type ['KFold'] 5\n",
      "    run 44   CV Type ['KFold'] 5\n",
      "    run 45   CV Type ['KFold'] 5\n",
      "    run 46   CV Type ['KFold'] 5\n",
      "    run 47   CV Type ['KFold'] 5\n",
      "    run 48   CV Type ['KFold'] 5\n",
      "    run 49   CV Type ['KFold'] 5\n",
      "    run 50   CV Type ['KFold'] 5\n",
      "    run 51   CV Type ['KFold'] 5\n",
      "    run 52   CV Type ['KFold'] 5\n",
      "    run 53   CV Type ['KFold'] 5\n",
      "    run 54   CV Type ['KFold'] 5\n",
      "    run 55   CV Type ['KFold'] 5\n",
      "    run 56   CV Type ['KFold'] 5\n",
      "    run 57   CV Type ['KFold'] 5\n",
      "    run 58   CV Type ['KFold'] 5\n",
      "    run 59   CV Type ['KFold'] 5\n",
      "    run 60   CV Type ['KFold'] 5\n",
      "    run 61   CV Type ['KFold'] 5\n",
      "    run 62   CV Type ['KFold'] 5\n",
      "    run 63   CV Type ['KFold'] 5\n",
      "    run 64   CV Type ['KFold'] 5\n",
      "    run 65   CV Type ['KFold'] 5\n",
      "    run 66   CV Type ['KFold'] 5\n",
      "    run 67   CV Type ['KFold'] 5\n",
      "    run 68   CV Type ['KFold'] 5\n",
      "    run 69   CV Type ['KFold'] 5\n",
      "    run 70   CV Type ['KFold'] 5\n",
      "    run 71   CV Type ['KFold'] 5\n",
      "    run 72   CV Type ['KFold'] 5\n",
      "    run 73   CV Type ['KFold'] 5\n",
      "    run 74   CV Type ['KFold'] 5\n",
      "    run 75   CV Type ['KFold'] 5\n",
      "    run 76   CV Type ['KFold'] 5\n",
      "    run 77   CV Type ['KFold'] 5\n",
      "    run 78   CV Type ['KFold'] 5\n",
      "    run 79   CV Type ['KFold'] 5\n",
      "    run 80   CV Type ['KFold'] 5\n",
      "    run 81   CV Type ['KFold'] 5\n",
      "    run 82   CV Type ['KFold'] 5\n",
      "    run 83   CV Type ['KFold'] 5\n",
      "    run 84   CV Type ['KFold'] 5\n",
      "    run 85   CV Type ['KFold'] 5\n",
      "    run 86   CV Type ['KFold'] 5\n",
      "    run 87   CV Type ['KFold'] 5\n",
      "    run 88   CV Type ['KFold'] 5\n",
      "    run 89   CV Type ['KFold'] 5\n",
      "    run 90   CV Type ['KFold'] 5\n",
      "    run 91   CV Type ['KFold'] 5\n",
      "    run 92   CV Type ['KFold'] 5\n",
      "    run 93   CV Type ['KFold'] 5\n",
      "    run 94   CV Type ['KFold'] 5\n",
      "    run 95   CV Type ['KFold'] 5\n",
      "    run 96   CV Type ['KFold'] 5\n",
      "    run 97   CV Type ['KFold'] 5\n",
      "    run 98   CV Type ['KFold'] 5\n",
      "    run 99   CV Type ['KFold'] 5\n",
      "    run 100   CV Type ['KFold'] 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b79693cafe7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mmodel_specs_vs_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecifications_master_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mtop_scores_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopSpecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_specs_vs_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/SatPRo/mlpros/classifier_cv/src/selectorFunctions.py\u001b[0m in \u001b[0;36mcallModels\u001b[0;34m(models_dict, scores_dict, specifications_master_dict, df, debug)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"machine_learning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mval_train_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallMLModels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_specs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;31m#handles the val_train_specs and losses for all the mlModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/SatPRo/mlpros/classifier_cv/src/mlHelpers.py\u001b[0m in \u001b[0;36mcallMLModels\u001b[0;34m(unique_specs_list, key_list, model_name, df, debug, models_dict, scores_dict)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'  CV Type'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0munique_specs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cross_validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_specs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'kFold_splits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mrun\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcallMLModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_specs_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_val_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_train_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"        Invalid Run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/SatPRo/mlpros/classifier_cv/src/mlHelpers.py\u001b[0m in \u001b[0;36mcallMLModel\u001b[0;34m(unique_specs_dict, model_name, df, debug, final_val_loss_list, final_train_loss_list, models_dict, scores_dict)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_specs_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_specs_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;31m#this has a list of train losses and val losses with appropriate keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/SatPRo/mlpros/classifier_cv/src/models/machineLearning/xgBoost.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainX, trainY, specifications, scores_dict)\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mpredictTrainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/automl_env/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/automl_env/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/automl_env/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/automl_env/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder = \"/Users/arpitjain/Downloads/SatPRo/2001_L7_data/ChangeClassifier/input_data\"\n",
    "for files in os.listdir(folder):\n",
    "    \n",
    "    df = pd.read_csv(os.path.join(folder, files))\n",
    "    data = ground_truth.merge(df, on='census_code', how='left')\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    target = files.split('_')[0] + '_change'\n",
    "    print('#### Running for : ',target)\n",
    "    \n",
    "    feature_cols = ['Formal_EMP_2001','LIT_2001','predictions_2001', 'predictions_2003','predictions_2005', 'predictions_2007', 'predictions_2009','predictions_2011']\n",
    "    \n",
    "    drop_cols = []\n",
    "    for col in data.columns:\n",
    "        if col in feature_cols:\n",
    "            continue\n",
    "        elif col == target:\n",
    "            continue\n",
    "        drop_cols.append(col)\n",
    "        \n",
    "#     print(type(drop_cols))\n",
    "    \n",
    "    print(target, drop_cols, feature_cols)\n",
    "    for key in specifications_master_dict.keys():\n",
    "               specifications_master_dict[key].update({\n",
    "                     'y_col': {\n",
    "                                 'value_type': 'constant',\n",
    "                                 'values': [target]},\n",
    "                     'current_date_col': {\n",
    "                                 'value_type': 'constant',\n",
    "                                 'values': drop_cols},\n",
    "                    'feature_cols': {\n",
    "                                        'value_type': 'constant',\n",
    "                                        'values': [feature_cols]},},\n",
    "               )\n",
    "    print('-------------------------------------')\n",
    "    print('-------------------------------------') \n",
    "    model_specs_vs_score = callModels(models_dict, scores_dict, specifications_master_dict, data, False)\n",
    "    top_scores_specs = topSpecs(model_specs_vs_score, scores_dict,get_train_score=True)\n",
    "    print('------------------------')\n",
    "    print(top_scores_specs['xgBoost']['val_scores'])\n",
    "    print(top_scores_specs['xgBoost']['train_scores'])\n",
    "    pickle.dump(top_scores_specs, open(target + '_CC_IncludeFormalEMP&LIT_XGB.pkl', 'wb'))\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
